{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eab4b576-6e0e-4442-b0db-ae5d021d1072",
   "metadata": {},
   "source": [
    "# Exercises \n",
    "\n",
    "1. What are the main tasks that autoencoders are used for?\n",
    "2. Suppose you want to train a classifier, & you have plenty of unlabeled training data but only a few thousand labeled instances. How can autoencoders help? How would you proceed?\n",
    "3. If an autoencoder perfectly reconstructs the inputs, is it necessarily a good autoencoder? How can you evaluate the performance of an autoencoder?\n",
    "4. What are undercomplete & overcomplete autoencoders? What is the main risk of an excessively undercomplete autoencoder? What about the main risk of an overcomplete autoencoder?\n",
    "5. How do you tie weights in a stacked autoencoder? What is the point of doing so?\n",
    "6. What is a generative model? Can you name a type of generative autoencoder?\n",
    "7. What is a GAN? Can you name a few tasks where GANs can shine?\n",
    "8. What are the main difficulties when training GANs?\n",
    "9. Try using a denoising autoencoder to pretrain an image classifier. You can use MNIST or a more complex image dataset such as CIFAR10. Regardless of the dataset you're using, follow these steps:\n",
    "   * Split the dataset into a training set & a test set. Train a deep denoising autoencoder on the full training set.\n",
    "   * Check that the images are fairly well reconstructed. Visualise the images that most activate each neuron in the coding layer.\n",
    "   * Build a classification DNN, reusing the lower layers of the autoencoder. Train it using only 500 images from the training set. Does it perform better with or without pretraining?\n",
    "10. Train a variational autoencoder on the image dataset of your choice, & use it to generate images. Alternatively, you can try to find an unlabeled dataset that you are interested in & see if you can generate new samples.\n",
    "11. Train a DCGAN to tackle the image dataset of your choice & use it to generate images. Add experience replay & see if this helps. Turn it into a conditional GAN where you can control the generated class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d043205-401b-4e2c-9084-c5abe8e86030",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f835d72d-414d-456b-aa90-7a0f8405cfdb",
   "metadata": {},
   "source": [
    "1. Autoencoders can be used for dimensionality reduction, especially for visualisation purposes. They can also act as feature detectors & can be used for unsupervised pretraining of deep neural networks. They can also be generative & are capable of generating new data that looks similar tot the training data.\n",
    "2. You can first train a stacked autoencoder using all the data, then reuse the lower layers to create a neural network for your actual classification task. This makes it possible to train a high-performance model using little training data because the resulting neural network won't have to learn all the low-level features; it will just reuse the feature detectors learned by the layers of the stacked autoencoder.\n",
    "3. If an autoencoder perfectly reconstructs its inputs, it doesnt necessarily mean that it is a good autoencoder. But if the autoencoder cannot reconstruct its inputs, then its a bad autoencoder. To assess the performance of an autoencoder, you can look at the reconstruction loss; you'd want a low reconstruction loss.\n",
    "4. An undercomplete autoencoder is an autoencoder whose codings have lower dimensions than the input data. An undercomplete autoencoder cannot trivially copy its inputs to the codings, so it must find a way to output a copy of the inputs. It is forced to learn the most important features in the input data & drop the unimportant ones. An overcomplete autoencoder is an autoencoder whose codings have equal or higher dimensions than the input data. Overcomplete autoencoders can be used for data visualisation or unsupervised pretraining, & learn important & interesting features like undercomplete autoencoders, but they can also remove noise from images. They can also be generative. An undercomplete autoencoder can fail to reconstruct the inputs, while the overcomplete autoencoder can just copy the inputs to the outputs, without learning any useful features.\n",
    "5. To tie the weights of an autoencoder, you transpose the weights of the encoder to the decoder. This makes training & convergence more efficient, because there are now half the number of parameters.\n",
    "6. Generative models are models that can generate new instances that look like instances in the training set. A variational autoencoder follows the basic structure of all autoencoders with an encoder followed by a decoder. However, instead of directly producing a coding for a given input, the encoder produces a mean coding $\\mu$ & a standard deviation $\\sigma$. The actual coding is then sampled randomly from a Gaussian distribution with mean $\\mu$ & standard deviation $\\sigma$. After that, the decoder decodes the sampled coding normally; & the final output resembles the training instance.\n",
    "7. A GAN puts two neural networks, a generator & discriminator, against each other, competing so that both excel. The generator takes a random distribution as input (typically Gaussian) & outputs data (typically an image). The discriminator takes either a generated image from the generator or the real image from the training set as input, & must guess whether the input image is fake or real. GANs can be great at image processing tasks like super resolution, colourisation, image editting, turning sketches into photorealistic images, & predicting the next frames of a video. They can also be used as a data augmentation technique by generating extra data such as text, audio, timeseries) & identify weaknesses in other models to strengthen them.\n",
    "8. The biggest difficulty of training a GAN is mode collapse. This is when the generator's output gradually become less diverse because the generator gets better at producing convincing images of one class than any other class, fooling the discriminator with a bit more images of that class & thus encouraging the generator to generate even more images of that class. Gradually, the network will forget how to produce anything else. Eventually, the generator will be forced to move to another class; it may then become very good at another class & the discriminator will follow. The GAN may gradually cycle across a few classes, never becoming very good at any of them. Moreover, because of the competition between the generator & the discriminator, the parameters can be unstable, so fine-tuning the hyperparameters becomes very sensitive & difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baed7e5a-2578-4e8b-b9c7-72bf9c308a34",
   "metadata": {},
   "source": [
    "# 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df4d573d-5e87-4305-9f38-c35ceef3928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "X_train = X_train / 255.0\n",
    "X_train, X_val = X_train[5000:], X_train[:5000]\n",
    "y_train, y_val = y_train[5000:], y_train[:5000]\n",
    "X_train_500, y_train_500 = X_train[:500], y_train[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75a5d4dd-a6ed-482c-b7cd-c26102acdd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoising_encoder = keras.models.Sequential([\n",
    "    keras.layers.Input(shape = [28, 28]),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Dense(300, activation = \"selu\"),\n",
    "    keras.layers.Dense(100, activation = \"selu\"),\n",
    "    keras.layers.Dense(30, activation = \"selu\")\n",
    "])\n",
    "denoising_decoder = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(shape = [30]),\n",
    "    keras.layers.Dense(100, activation = \"selu\"),\n",
    "    keras.layers.Dense(300, activation = \"selu\"),\n",
    "    keras.layers.Dense(784, activation = \"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "\n",
    "denoising_autoencoder = keras.models.Sequential([denoising_encoder, denoising_decoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68f87bf-9cf5-40af-857b-e52fd4e134ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.2249 - val_loss: 0.1369\n",
      "Epoch 2/15\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.1415 - val_loss: 0.1197\n",
      "Epoch 3/15\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.1294 - val_loss: 0.1123\n",
      "Epoch 4/15\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.1223 - val_loss: 0.1070\n",
      "Epoch 5/15\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: 0.1179 - val_loss: 0.1038\n",
      "Epoch 6/15\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: 0.1147 - val_loss: 0.1012\n",
      "Epoch 7/15\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.1123 - val_loss: 0.0988\n",
      "Epoch 8/15\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: 0.1100 - val_loss: 0.0984\n",
      "Epoch 9/15\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.1083 - val_loss: 0.0969\n",
      "Epoch 10/15\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.1071 - val_loss: 0.0963\n",
      "Epoch 11/15\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.1056 - val_loss: 0.0937\n",
      "Epoch 12/15\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.1047 - val_loss: 0.0948\n",
      "Epoch 13/15\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.1036 - val_loss: 0.0937\n",
      "Epoch 14/15\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.1027 - val_loss: 0.0930\n",
      "Epoch 15/15\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.1019 - val_loss: 0.0932\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"best_denoising_autoencoder.keras\", \n",
    "                                                save_best_only = True)\n",
    "\n",
    "denoising_autoencoder.compile(loss = \"binary_crossentropy\", \n",
    "                              optimizer = keras.optimizers.SGD(learning_rate = 1.0))\n",
    "history = denoising_autoencoder.fit(X_train, X_train, epochs = 15,\n",
    "                                    validation_data = (X_val, X_val),\n",
    "                                   callbacks = [checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99f11361-3d5a-41c2-b2c6-cabbde9b1ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x1000 with 15 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_images = 5\n",
    "new_images = X_test[:n_images]\n",
    "new_images_noisy = new_images + np.random.randn(n_images, 28, 28) * 0.1\n",
    "new_images_denoised = denoising_autoencoder.predict(new_images_noisy)\n",
    "\n",
    "plt.figure(figsize = (6, n_images * 2))\n",
    "for index in range(n_images):\n",
    "    plt.subplot(n_images, 3, index * 3 + 1)\n",
    "    plt.imshow(new_images[index])\n",
    "    plt.axis(\"off\")\n",
    "    if index == 0:\n",
    "        plt.title(\"Original\")\n",
    "    plt.subplot(n_images, 3, index * 3 + 2)\n",
    "    plt.imshow(np.clip(new_images_noisy[index], 0., 1.))\n",
    "    plt.axis(\"off\")\n",
    "    if index == 0:\n",
    "        plt.title(\"Noisy\")\n",
    "    plt.subplot(n_images, 3, index * 3 + 3)\n",
    "    plt.imshow(new_images_denoised[index])\n",
    "    plt.axis(\"off\")\n",
    "    if index == 0:\n",
    "        plt.title(\"Denoised\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72bee4bf-a707-4742-ab0e-801af0267bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_NN = keras.models.Sequential([\n",
    "    keras.layers.Input(shape = [28, 28]),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(300, activation = \"relu\"),\n",
    "    keras.layers.Dense(100, activation = \"relu\"),\n",
    "    keras.layers.Dense(10, activation = \"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ae790b4-2122-4ffe-a560-7bb677a469e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.1323 - loss: 2.2924 - val_accuracy: 0.1338 - val_loss: 2.2761\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1617 - loss: 2.2560 - val_accuracy: 0.1474 - val_loss: 2.2615\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1506 - loss: 2.2687 - val_accuracy: 0.1624 - val_loss: 2.2474\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1832 - loss: 2.2184 - val_accuracy: 0.1774 - val_loss: 2.2336\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1974 - loss: 2.2093 - val_accuracy: 0.1948 - val_loss: 2.2202\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2001 - loss: 2.1952 - val_accuracy: 0.2148 - val_loss: 2.2071\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2394 - loss: 2.1765 - val_accuracy: 0.2302 - val_loss: 2.1944\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2656 - loss: 2.1411 - val_accuracy: 0.2520 - val_loss: 2.1818\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2594 - loss: 2.1604 - val_accuracy: 0.2686 - val_loss: 2.1696\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3553 - loss: 2.1141 - val_accuracy: 0.2820 - val_loss: 2.1575\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3496 - loss: 2.1162 - val_accuracy: 0.3046 - val_loss: 2.1455\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3325 - loss: 2.1159 - val_accuracy: 0.3226 - val_loss: 2.1336\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3777 - loss: 2.0930 - val_accuracy: 0.3390 - val_loss: 2.1219\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3681 - loss: 2.0824 - val_accuracy: 0.3546 - val_loss: 2.1102\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4216 - loss: 2.0540 - val_accuracy: 0.3688 - val_loss: 2.0986\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3915 - loss: 2.0701 - val_accuracy: 0.3856 - val_loss: 2.0872\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4373 - loss: 2.0151 - val_accuracy: 0.3992 - val_loss: 2.0756\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4688 - loss: 2.0045 - val_accuracy: 0.4130 - val_loss: 2.0641\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5054 - loss: 1.9884 - val_accuracy: 0.4244 - val_loss: 2.0526\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5253 - loss: 1.9578 - val_accuracy: 0.4338 - val_loss: 2.0413\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5224 - loss: 1.9486 - val_accuracy: 0.4428 - val_loss: 2.0298\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5184 - loss: 1.9473 - val_accuracy: 0.4532 - val_loss: 2.0183\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5019 - loss: 1.9424 - val_accuracy: 0.4588 - val_loss: 2.0069\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5418 - loss: 1.9143 - val_accuracy: 0.4664 - val_loss: 1.9954\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5702 - loss: 1.9015 - val_accuracy: 0.4746 - val_loss: 1.9840\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5769 - loss: 1.8869 - val_accuracy: 0.4834 - val_loss: 1.9727\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5559 - loss: 1.8840 - val_accuracy: 0.4894 - val_loss: 1.9612\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6005 - loss: 1.8572 - val_accuracy: 0.4968 - val_loss: 1.9497\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5856 - loss: 1.8635 - val_accuracy: 0.5048 - val_loss: 1.9381\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5639 - loss: 1.8563 - val_accuracy: 0.5112 - val_loss: 1.9266\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5837 - loss: 1.8254 - val_accuracy: 0.5172 - val_loss: 1.9150\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5900 - loss: 1.8135 - val_accuracy: 0.5240 - val_loss: 1.9034\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6088 - loss: 1.8095 - val_accuracy: 0.5284 - val_loss: 1.8918\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6128 - loss: 1.7576 - val_accuracy: 0.5366 - val_loss: 1.8801\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6149 - loss: 1.7666 - val_accuracy: 0.5426 - val_loss: 1.8685\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6053 - loss: 1.7795 - val_accuracy: 0.5476 - val_loss: 1.8568\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6490 - loss: 1.7336 - val_accuracy: 0.5528 - val_loss: 1.8451\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6319 - loss: 1.7383 - val_accuracy: 0.5582 - val_loss: 1.8334\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6352 - loss: 1.7099 - val_accuracy: 0.5654 - val_loss: 1.8217\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6589 - loss: 1.6929 - val_accuracy: 0.5712 - val_loss: 1.8101\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6810 - loss: 1.6556 - val_accuracy: 0.5754 - val_loss: 1.7985\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6855 - loss: 1.6563 - val_accuracy: 0.5830 - val_loss: 1.7868\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6321 - loss: 1.6790 - val_accuracy: 0.5888 - val_loss: 1.7751\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6711 - loss: 1.6458 - val_accuracy: 0.5952 - val_loss: 1.7635\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6840 - loss: 1.6284 - val_accuracy: 0.5994 - val_loss: 1.7520\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6685 - loss: 1.6031 - val_accuracy: 0.6054 - val_loss: 1.7405\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7241 - loss: 1.5793 - val_accuracy: 0.6082 - val_loss: 1.7290\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7067 - loss: 1.5763 - val_accuracy: 0.6124 - val_loss: 1.7176\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7291 - loss: 1.5489 - val_accuracy: 0.6166 - val_loss: 1.7062\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7123 - loss: 1.5784 - val_accuracy: 0.6206 - val_loss: 1.6947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x150507ec0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_NN.compile(loss = \"sparse_categorical_crossentropy\",\n",
    "                 optimizer = keras.optimizers.SGD(learning_rate = 1e-3), \n",
    "                 metrics = [\"accuracy\"])\n",
    "class_NN.fit(X_train_500, y_train_500, epochs = 50,\n",
    "             validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7906a800-fd86-4d42-9570-6376d63dac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoising_model = keras.models.load_model(\"best_denoising_autoencoder.keras\")\n",
    "combined_model = keras.models.Sequential([denoising_model, class_NN])\n",
    "denoising_model_clone = keras.models.clone_model(denoising_model)\n",
    "denoising_model_clone.set_weights(denoising_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a0bdb6f-8234-4025-8994-7ebfe6fcf2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6968 - loss: 0.0000e+00 - val_accuracy: 0.8034 - val_loss: 0.0000e+00\n",
      "Epoch 2/15\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8688 - loss: 0.0000e+00 - val_accuracy: 0.8522 - val_loss: 0.0000e+00\n",
      "Epoch 3/15\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8951 - loss: 0.0000e+00 - val_accuracy: 0.8512 - val_loss: 0.0000e+00\n",
      "Epoch 4/15\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9209 - loss: 0.0000e+00 - val_accuracy: 0.8664 - val_loss: 0.0000e+00\n",
      "Epoch 5/15\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9330 - loss: 0.0000e+00 - val_accuracy: 0.8738 - val_loss: 0.0000e+00\n",
      "Epoch 6/15\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9663 - loss: 0.0000e+00 - val_accuracy: 0.8694 - val_loss: 0.0000e+00\n",
      "Epoch 7/15\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9778 - loss: 0.0000e+00 - val_accuracy: 0.8750 - val_loss: 0.0000e+00\n",
      "Epoch 8/15\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9832 - loss: 0.0000e+00 - val_accuracy: 0.8702 - val_loss: 0.0000e+00\n",
      "Epoch 9/15\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9846 - loss: 0.0000e+00 - val_accuracy: 0.8798 - val_loss: 0.0000e+00\n",
      "Epoch 10/15\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9784 - loss: 0.0000e+00 - val_accuracy: 0.8812 - val_loss: 0.0000e+00\n",
      "Epoch 11/15\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9863 - loss: 0.0000e+00 - val_accuracy: 0.8742 - val_loss: 0.0000e+00\n",
      "Epoch 12/15\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9891 - loss: 0.0000e+00 - val_accuracy: 0.8790 - val_loss: 0.0000e+00\n",
      "Epoch 13/15\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9915 - loss: 0.0000e+00 - val_accuracy: 0.8790 - val_loss: 0.0000e+00\n",
      "Epoch 14/15\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9854 - loss: 0.0000e+00 - val_accuracy: 0.8850 - val_loss: 0.0000e+00\n",
      "Epoch 15/15\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9970 - loss: 0.0000e+00 - val_accuracy: 0.8732 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1508a9bb0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in combined_model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "combined_model.compile(loss = \"sparse_categorical_crossentropy\",\n",
    "                       optimizer = \"nadam\", metrics = [\"accuracy\"])\n",
    "combined_model.fit(X_train_500, y_train_500, epochs = 15,\n",
    "                   validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4e1ace7-d358-4eae-98d2-9c722194df94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.9918 - loss: 0.0000e+00 - val_accuracy: 0.8792 - val_loss: 0.0000e+00\n",
      "Epoch 2/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9851 - loss: 0.0000e+00 - val_accuracy: 0.8924 - val_loss: 0.0000e+00\n",
      "Epoch 3/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9962 - loss: 0.0000e+00 - val_accuracy: 0.8856 - val_loss: 0.0000e+00\n",
      "Epoch 4/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9982 - loss: 0.0000e+00 - val_accuracy: 0.8840 - val_loss: 0.0000e+00\n",
      "Epoch 5/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9954 - loss: 0.0000e+00 - val_accuracy: 0.8756 - val_loss: 0.0000e+00\n",
      "Epoch 6/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9961 - loss: 0.0000e+00 - val_accuracy: 0.8650 - val_loss: 0.0000e+00\n",
      "Epoch 7/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9783 - loss: 0.0000e+00 - val_accuracy: 0.8878 - val_loss: 0.0000e+00\n",
      "Epoch 8/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9945 - loss: 0.0000e+00 - val_accuracy: 0.8700 - val_loss: 0.0000e+00\n",
      "Epoch 9/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9868 - loss: 0.0000e+00 - val_accuracy: 0.8776 - val_loss: 0.0000e+00\n",
      "Epoch 10/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9821 - loss: 0.0000e+00 - val_accuracy: 0.8754 - val_loss: 0.0000e+00\n",
      "Epoch 11/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9981 - loss: 0.0000e+00 - val_accuracy: 0.8802 - val_loss: 0.0000e+00\n",
      "Epoch 12/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9966 - loss: 0.0000e+00 - val_accuracy: 0.8864 - val_loss: 0.0000e+00\n",
      "Epoch 13/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9914 - loss: 0.0000e+00 - val_accuracy: 0.8904 - val_loss: 0.0000e+00\n",
      "Epoch 14/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9990 - loss: 0.0000e+00 - val_accuracy: 0.8858 - val_loss: 0.0000e+00\n",
      "Epoch 15/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9933 - loss: 0.0000e+00 - val_accuracy: 0.8874 - val_loss: 0.0000e+00\n",
      "Epoch 16/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9970 - loss: 0.0000e+00 - val_accuracy: 0.8924 - val_loss: 0.0000e+00\n",
      "Epoch 17/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9920 - loss: 0.0000e+00 - val_accuracy: 0.8778 - val_loss: 0.0000e+00\n",
      "Epoch 18/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9893 - loss: 0.0000e+00 - val_accuracy: 0.8816 - val_loss: 0.0000e+00\n",
      "Epoch 19/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9910 - loss: 0.0000e+00 - val_accuracy: 0.8922 - val_loss: 0.0000e+00\n",
      "Epoch 20/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9934 - loss: 0.0000e+00 - val_accuracy: 0.8952 - val_loss: 0.0000e+00\n",
      "Epoch 21/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9981 - loss: 0.0000e+00 - val_accuracy: 0.8750 - val_loss: 0.0000e+00\n",
      "Epoch 22/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9979 - loss: 0.0000e+00 - val_accuracy: 0.8920 - val_loss: 0.0000e+00\n",
      "Epoch 23/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 0.8962 - val_loss: 0.0000e+00\n",
      "Epoch 24/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9954 - loss: 0.0000e+00 - val_accuracy: 0.8706 - val_loss: 0.0000e+00\n",
      "Epoch 25/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9808 - loss: 0.0000e+00 - val_accuracy: 0.8718 - val_loss: 0.0000e+00\n",
      "Epoch 26/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9887 - loss: 0.0000e+00 - val_accuracy: 0.8780 - val_loss: 0.0000e+00\n",
      "Epoch 27/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9937 - loss: 0.0000e+00 - val_accuracy: 0.8808 - val_loss: 0.0000e+00\n",
      "Epoch 28/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9924 - loss: 0.0000e+00 - val_accuracy: 0.8604 - val_loss: 0.0000e+00\n",
      "Epoch 29/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9844 - loss: 0.0000e+00 - val_accuracy: 0.8856 - val_loss: 0.0000e+00\n",
      "Epoch 30/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9992 - loss: 0.0000e+00 - val_accuracy: 0.8884 - val_loss: 0.0000e+00\n",
      "Epoch 31/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9907 - loss: 0.0000e+00 - val_accuracy: 0.8788 - val_loss: 0.0000e+00\n",
      "Epoch 32/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9941 - loss: 0.0000e+00 - val_accuracy: 0.8908 - val_loss: 0.0000e+00\n",
      "Epoch 33/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9969 - loss: 0.0000e+00 - val_accuracy: 0.8880 - val_loss: 0.0000e+00\n",
      "Epoch 34/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9977 - loss: 0.0000e+00 - val_accuracy: 0.8932 - val_loss: 0.0000e+00\n",
      "Epoch 35/35\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9965 - loss: 0.0000e+00 - val_accuracy: 0.8884 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x150ac9700>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in combined_model.layers[:-1]:\n",
    "    layer_trainable = True\n",
    "\n",
    "combined_model.compile(loss = \"sparse_categorical_crossentropy\",\n",
    "                       optimizer = \"nadam\", metrics = [\"accuracy\"])\n",
    "combined_model.fit(X_train_500, y_train_500, epochs = 35,\n",
    "                   validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4716ec-7209-4927-b022-2f9b4e2b30e7",
   "metadata": {},
   "source": [
    "# 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51319932-5de9-469c-931e-dc4f2259af78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        mean, log_var = inputs\n",
    "        return keras.backend.random_normal(tf.shape(log_var)) * tf.exp(log_var/2) + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0ee634-210d-4a5a-a73c-2f1451414bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "codings_size = 10\n",
    "\n",
    "inputs = keras.layers.Input(shape = [28, 28])\n",
    "z = keras.layers.Flatten()(inputs)\n",
    "z = keras.layers.Dense(150, activation = \"selu\")(z)\n",
    "z = keras.layers.Dense(100, activation = \"selu\")(z)\n",
    "codings_mean = keras.layers.Dense(codings_size)(z)\n",
    "codings_log_var = keras.layers.Dense(codings_size)(z)\n",
    "codings = Sampling()([codings_mean, codings_log_var])\n",
    "variational_encoder = keras.Model(inputs = [inputs], \n",
    "                                  outputs = [codings_mean, codings_log_var, codings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da99f0ce-39cd-459c-9d7c-883a53280430",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = keras.layers.Input(shape = [codings_size])\n",
    "x = keras.layers.Dense(100, activation = \"selu\")(decoder_inputs)\n",
    "x = keras.layers.Dense(150, activation = \"selu\")(x)\n",
    "x = keras.layers.Dense(784, activation = \"sigmoid\")(x)\n",
    "outputs = keras.layers.Reshape([28, 28])(x)\n",
    "variational_decoder = keras.Model(inputs = [decoder_inputs],\n",
    "                                  outputs = [outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc274d-72bb-4c4c-be9f-5e24b55ac614",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, codings = variational_encoder(inputs)\n",
    "reconstructions = variational_decoder(codings)\n",
    "variational_autoencoder = keras.Model(inputs = [inputs], outputs = [reconstructions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba837d6f-571f-4dd3-bf72-1c2bdbb06b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "latent_loss = -0.5 * K.sum(\n",
    "    1 + codings_log_var - K.exp(codings_log_var) - K.square(codings_mean),\n",
    "                           axis = -1)\n",
    "variational_autoencoder.add_loss(K.mean(latent_loss) / 784.)\n",
    "variational_autoencoder.compile(loss = \"binary_crossentropy\", optimizer = \"rmsprop\")\n",
    "variational_autoencoder.fit(X_train, y_train, epochs = 20, batch_size = 128,\n",
    "                            validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23d0ecd-7ba3-4ba7-a535-373940669718",
   "metadata": {},
   "source": [
    "# 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c092979-9972-4a25-b015-caa196f5f0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "codings_size = 100\n",
    "\n",
    "generator = keras.models.Sequential([\n",
    "    keras.layers.Input(shape = [codings_size]),\n",
    "    keras.layers.Dense(6272, activation = \"relu\"),\n",
    "    keras.layers.Reshape([7, 7, 128]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(64, kernel_size = 5, strides = 2, \n",
    "                                padding = \"same\", activation = \"selu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(1, kernel_size = 5, strides = 2,\n",
    "                                padding = \"same\", activation = \"tanh\")\n",
    "])\n",
    "discriminator = keras.models.Sequential([\n",
    "    keras.layers.Input(shape = [28, 28, 1]),\n",
    "    keras.layers.Conv2D(64, kernel_size = 5, strides = 2,\n",
    "                        padding = \"same\", activation = keras.layers.LeakyReLU(0.2)),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Conv2D(128, kernel_size = 5, strides = 2,\n",
    "                        padding = \"same\", activation = keras.layers.LeakyReLU(0.2)),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1, activation = \"sigmoid\")\n",
    "])\n",
    "\n",
    "dcgan = keras.models.Sequential([generator, discriminator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c25a44b-3965-4cbb-8e4a-64a9736d5aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss = \"binary_crossentropy\", optimizer = \"rmsprop\")\n",
    "discriminator.trainable = False\n",
    "dcgan.compile(loss = \"binary_crossentropy\", optimizer = \"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71a12e4-0810-467b-800b-53501d1653c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reshaped = X_train.reshape(-1, 28, 28, 1) * 2. - 1.\n",
    "\n",
    "batch_size = 32\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X_train_reshaped).shuffle(1000)\n",
    "dataset = dataset.batch(batch_size, drop_remainder = True).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8100b157-00c4-48c3-9737-9b87b73edcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(gan, dataset, batch_size, codings_size, n_epochs = 25):\n",
    "    generator, discriminator = gan.layers\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))              # not shown in the book\n",
    "        for X_batch in dataset:\n",
    "            # Phase 1 - Training the discriminator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            generated_images = generator(noise)\n",
    "            X_fake_and_real = tf.concat([generated_images, X_batch], axis = 0)\n",
    "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
    "            discriminator.trainable = True\n",
    "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
    "            # Phase 2 - Training the generator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            y2 = tf.constant([[1.]] * batch_size)\n",
    "            discriminator.trainable = False\n",
    "            gan.train_on_batch(noise, y2)\n",
    "        plot_multiple_images(generated_images, 8)                     # not shown\n",
    "        plt.show()\n",
    "\n",
    "train_gan(dcgan, dataset, batch_size, codings_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeacd025-3ed2-4367-ab9e-e93c152b67e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
