{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11ecf1a6-9637-4955-9278-211ff2849b60",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "1. How would you describe TensorFlow in a short sentence? What are its main features? Can you name other popular deep learning libraries?\n",
    "2. Is TensorFlow a drop-in replacement for NumPy? What are the main differences between the two?\n",
    "3. Do you get the same result with `tf.range(10)` & `tf.constant(np.arange(10))`?\n",
    "4. Can you name six other data structures available in TensorFlow, beyond regular tensors?\n",
    "5. A custom loss function can be defined by writing a function or by subclassing the `keras.losses.Loss` class. When would you use each option?\n",
    "6. Similarly, a custom metric can be defined in a function or a subclass of `keras.metrics.Metric`. When would you use each option?\n",
    "7. When should you create a custom layer versus a custom model?\n",
    "8. What are some use cases that require writing your own custom training loop?\n",
    "9. Can custom keras components contain arbitrary python code, or must they be convertible to tf functions?\n",
    "10. What are the main rules to respect if you want a function to be convertible to a tf function?\n",
    "11. When would you need to create a dynamic keras model? How do you do that? Why not make all your models dynamic?\n",
    "12. Implement a custom layer that performs *Layer Normalisation*:\n",
    "   * The `build()` method should define two trainable weights $\\alpha$ & $\\beta$, both of shape `input_shape[-1:]` & data type `tf.float32`. $\\alpha$ should be initialised with 1s & $\\beta$ with 0s.\n",
    "   * The `call()` method should compute the mean $\\mu$ & standard deviation $\\sigma$ of each instance's features. For this, you can use `tf.nn.moments(inputs, axes = -1, keepdims = True)`, which returns the mean $\\mu$ & the variance $\\sigma^2$ of all instances (compute the square root of the variance to get the standard deviation). Then the function should compute & return $\\alpha \\otimes (X - \\mu)/(\\sigma + \\varepsilon) + \\beta$, where $\\otimes$ represents itemwise multiplication ($*$) & $\\varepsilon$ is a smoothing term (small constant to avoid division by zero, e.g., 0.001).\n",
    "   * Ensure that your custom layer produces the same (or very nearly the same) output as the `keras.layers.LayerNormalization` layer.\n",
    "13. Train a model using a custom training loop to tackle the fashion MNIST dataset.\n",
    "   * Display the epoch, iteration, mean training loss, & mean accuracy over each epoch (updated at each iteration), as well as the validation loss & accuracy at the end of each epoch.\n",
    "   * Try using a different optimiser with a different learning rate for the upper layers & the lower layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37315d99-76f2-4492-92f9-feaf772ee864",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c38cff-8387-4b49-9bdc-b83d3b4b110e",
   "metadata": {},
   "source": [
    "1. TensorFlow is a powerful library for large-scale machine learning or mathematical computation, that is also at the center of an ecosystem of libraries built for data validation, visualisation, preprocessing, all backed by a dedicated team of passionate developers & a large community contributing to improving it. It's core features include GPU support for multithreading, distributed computing (across multiple devices & servers), computation optimisation (for speed & memory usage), exportable computation graphs (train TensorFlow models in one environment (Python on Linux) & run it in another (Java on Android)), reverse-mode autodiff implementations, & optimisers (RMSProp & Nadam). Other popular deep learning libraries include pytorch & mxnet.\n",
    "2. While TensorFlow can perform many of the same math operations as NumPy can, their differences lie mainly in the data types. TensorFlow is much stricter on performing operations with different data types. For example, in NumPy, you can add a float with an integer; but in TensorFlow, you cannot, because they are different data types. This is because when training large neural networks, type conversions can significantly increase training time, so TensorFlow will not automatically convert your data type. It will raise an exception if you execute an operation with incompatible types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a596a593-5a71-4395-a5c5-e24e475ebb9f",
   "metadata": {},
   "source": [
    "# 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da36bf8a-c60c-4813-a369-83aa43d14bb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "398c31f3-f051-4e7c-a1af-ad8c2a154fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "tf.constant(np.arange(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd9dd2d-395b-443a-809d-87af39770b8b",
   "metadata": {},
   "source": [
    "Yes, they seem the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7ce58b-d909-48b3-bf2a-b9d3c20218d1",
   "metadata": {},
   "source": [
    "4. TensorFlow supports several other data structures, beside regular tensors: *sparse tensors* (efficiently represent tensors containing mostly 0s), *tensor arrays* (lists of tensors of a fixed size, *all tensors must have the same shape & data type), *ragged tensors* (static lists of lists of tensors, where every tensor has the same shape & data type), *string tensors* (regular tensors of type `tf.string`), *sets* (regular or sparse tensors containing multiple sets of values {ex: `tf.constant([[1, 2], [3, 4]])` contains two sets {1, 2} & {3, 4}), & *queues* (store tensors across multiple steps).\n",
    "5. If you create a custom loss function by writing a python function, the model containing your custom loss function can be saved & loaded, but you would have to manually set your loss function's hyperparameters every time you load your model. In other words, the hyperparameters of your custom loss function will not be saved. You can save the hyperparameters of your loss function along with your model by creating a subclass of the `keras.losses.Loss` class & implementing its `__init__()`, `call()`, & `get_config()` method. When you load your model this way, you just need to map the class name to the class, same as you would for a python function, but with a python function, you would have the specify the value for the hyperparameter.\n",
    "6. Similar to loss functions, subclassing `keras.metrics.Metric` will save your metric's hyperparameters along with your model. Also, for metrics that cannot be averaged over batches, like precision, you must implement a streaming metric, which requires you to subclass `keras.metrics.Metric`. If you do not want to save your metrics hyperparameters along with the model, or your metric can be averaged over batches, then a simple python function will suffice.\n",
    "7. You should create custom layers or custom blocks of layers if your model's architecture is very repetitive. For custom layers with no weights, you could wrap it in a `keras.layers.Lambda` layer, but with weights, you would subclass the `keras.layers.Layer` class. You should create a custom model if the model's architecture cannot be created given the tools of keras. For custom models, you should subclass the `keras.models.Model` class.\n",
    "8. You might write a custom training loop if you want full control of of the training process, or if you just want to understand what's going on during model training, or if you want to use different optimisers for different parts of your neural network, like for the wide & deep example. Most of the time though, you want to avoid writing custom training loops because they are error-prone; you need to make sure a lot of thing are right for the loop to function properly.\n",
    "9. When you write a custom loss function, metric, layer, or any other function & use it in a keras model, it will automatically be converted into a tf function for more efficient execution. Most of the time though, you can either decorate your python function with `@tf.function` or let keras handle it. For arbitrary python code, you should wrap it in `tf.py_function()`. This will hinder efficiency & portability, because TensorFlow cannot perform graph optimisations on the code & the graph will only run on platforms where python is available.\n",
    "10. (1) Use TensorFlow constructs as much as you can. For arbitrary python code, wrap it in a `tf.py_function()` operation. (2) Create variables outside of the tf function (e.g., in the `build()` method of a custom layer. If you want to assign a new value to the variable, call its `assign()` method instead of using the `=` operator. (3) The source code of your python function should be available to TensorFlow. (4) Make sure your loops iterate over a tensor or a dataset (Use `for i in tf.range(x)` instead of `for i in range(x)` so that the graph will be optimised). (5) Use vectorised implementations to optimise for efficiency.\n",
    "11. To create a dynamic keras model, set `dynamic = True` when creating the model. Alternatively, you can set `run_eagerly = True` when calling the model's `compile()` method. You might create a dynamic model for help in debugging, but it really slows down the training process, because the model will not create a graph for efficiency optimisation.\n",
    "\n",
    "# 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97d9a676-6b3b-4165-a238-8f48817b8862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "class LayerNormalisation(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        self.alpha = self.add_weight(name = \"alpha\", shape = input_shape[-1:],\n",
    "                                     initializer = \"Ones\") # keras.initializers.Ones()\n",
    "        self.beta = self.add_weight(name = \"beta\", shape = input_shape[-1:],\n",
    "                                    initializer = \"Zeros\") # keras.initializers.Zeros()\n",
    "        super().build(input_shape) # must have at the end\n",
    "    def call(self, inputs):\n",
    "        mean, var = tf.nn.moments(inputs, axes = -1, keepdims = True)\n",
    "        return self.alpha * (inputs - mean)/(tf.sqrt(var + 0.001)) + self.beta\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tf.TensorShape(input_shape.as_list()[:-1])\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc0cda13-e466-4a61-8150-f100f4489370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=4.2290893e-08>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train, X_test, y_train, y_test = train_test_split(housing.data, housing.target.reshape(-1, 1))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train)\n",
    "\n",
    "X = X_train.astype(np.float32)\n",
    "\n",
    "custom_layernorm = LayerNormalisation()\n",
    "keras_layernorm = keras.layers.LayerNormalization()\n",
    "\n",
    "tf.reduce_mean(keras.losses.mean_absolute_error(keras_layernorm(X), \n",
    "                                                custom_layernorm(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce2ceeb-086e-4b6c-83c0-b9ef5c05d14b",
   "metadata": {},
   "source": [
    "# 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf62da4a-b342-4eb8-a87c-f958acd5a7f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "X_train, y_train = X_train[6000:] / 255.0, y_train[6000:] / 255.0\n",
    "X_val, y_val = X_train[:6000] / 255.0, y_train[:6000] / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fa6cc72-c564-4b75-8d8d-f2f5db4a5f7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">78,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m78,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">220,910</span> (862.93 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m220,910\u001b[0m (862.93 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">220,910</span> (862.93 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m220,910\u001b[0m (862.93 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = (28, 28)))\n",
    "for _ in range(15):\n",
    "    model.add(keras.layers.Dense(100, activation = \"selu\", kernel_initializer = \"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation = \"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50460209-f5f0-43be-9a41-45fffddb7609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def random_batch(X, y, batch_size = 32):\n",
    "    num_id = np.random.randint(len(X), size = batch_size)\n",
    "    return X[num_id], y[num_id]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
