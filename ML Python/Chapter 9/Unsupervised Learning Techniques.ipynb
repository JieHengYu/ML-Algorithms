{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a491f6b-b8f9-4469-a0d9-753497f30431",
   "metadata": {},
   "source": [
    "# Unsupervised Learning Techniques\n",
    "\n",
    "Although most of the applications of machine learning today are based on supervised learning (& as a result, this is where most of the investments go to), the vast majority of the available data is unlabeled: we have the input features $X$, but we do not have the labels $y$. The computer scientist Yann LeCun famously said that \"if intelligence was a cake, unsupervised learning would be the cake, supervised learning would be the icing on the cake, & reinforcement learning would be the cherry on the cake.\" In other words, there is a huge potential in unsupervised learning that we have only barely started to sink our teeth into.\n",
    "\n",
    "Say you want to create a system that will take a few pictures of each item on a manufacturing production line & detect which items are defective. You can fairly easily create a system that will take pictures automatically, & this might give you thousands of pictures every day. you can then build a reasonably large dataset in just a few weeks. But wait, there is no labels! If you want to train a regular binary classifier that will predict whether an item is defective or not, you will need to label every single picture as 'defective\" or \"normal\". This will generally require human experts to sit down & manually go through all the pictures. This is a long, costly, & tedious task, so it will usually only be done ona small subset of available pictures. As a result, the labeled dataset will be quite small, & the classifier's performance will be disappointing. Moreover, every time the company makes any change to its products, the whole process will need to be started over from scratch. Wouldn't it be great if the algorithm could just exploit the unlabeled data without needing humans to label every picture? Enter unsupervised learning.\n",
    "\n",
    "In this lesson, we will look at a few unsupervised learning tasks & algorithms:\n",
    "\n",
    "* *Clustering*\n",
    "   - The goal is to group similar instance together into *clusters*. Clustering is a great tool for data analysis, customer segmentation, recommender systems, search engines, image segmentation, semi-supervised learning, dimensionality reduction, & more.\n",
    "* *Anomaly detection*\n",
    "   - The objective is to learn what \"normal\" data looks like, & then use that to detect abnormal instances, such as defective items on a production line or a new trend in a time series.\n",
    "* *Density estimation*\n",
    "   - This is the task of estimating the *probability density function* (PDF) of the random process that generated the dataset. Density estimation of commonly used for anomaly detection: instances located in very low-density regions are likely to be anomalies. It is also useful for data analysis & visualisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44afcdb-911b-4a41-8e4c-302022926908",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c8e3c2-5c10-44af-bdc6-10478180ea83",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "As you enjoy a hike in the mountains, you stumble upon a plant you have never seen before. You look around & you notice a few more. They are not identical, yet they are sufficiently similar for you to know that they most likely belong to the same species (or at least the same genus). You may need a botanist to tell you what species that is, but you certainly don't need an expert to identify groups of similar-looking objects. This is called *clustering*: it is the task of identifying similar instances & assigning them to *clusters*, or groups of similar instances.\n",
    "\n",
    "Just like in classification, each instance gets assigned to a group. However, unlike classification, clustering is an unsupervised task. \n",
    "\n",
    "<img src = \"Images/Classification vs Clustering.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "Consider the left diagram in the figure: on the left is the iris dataset, where each instance's species is represented with a different marker. It is a labeled dataset, for which classification algorithms such as logistic regression, SVMs, or random forest classifiers are well suited. On the right is the same dataset, but without labels, so you cannot use classification algorithm anymore. This is where clustering algorithms step in: many of them can easily detect the lower-left cluster. It is also quite easy to see with your own eyes, but it is not so obvious that the upper-right cluster is composed of two distinct sub-clusters. That siad, the dataset has two additional features (sepal length & width), not represented here, & clustering algorithms can make good use of all features, so in fact they identify the three clusters fairly well (e.g., using a Gaussian mixture model, only 5 instances out of 150 are assigned to the wrong cluster).\n",
    "\n",
    "Clustering is used in a wide variety of applications, including these:\n",
    "\n",
    "* *For customer segmentation*\n",
    "   - You can cluster your customers based on their purchases & their activity on your website. This is useful to understand who your customers are & what they need, so you can adapt your products & marketing campaigns to each segment. For example, customer segmentation can be useful in *recommender systems* to suggest content that other users in the same cluster enjoyed.\n",
    "* *For data analysis*\n",
    "   - When you analyse a new dataset, it can be helpful to run a clustering algorithm, & then analyse each cluster separately.\n",
    "* *As a dimensionality reduction technique*\n",
    "   - Once a dataset has been clustered, it is usually possible to measure each instance's *affinity* with each cluster (affinity is a measure of how well an instance fits into a cluster). Each instance's feature vector $x$ can then be replaced with the vector of its cluster affinities. If there are *k* clusters,then this vector is *k*-dimensional. This vector is typically much lower-dimensional than the original feature vector, but it can preserve enough information for further processing.\n",
    "* *For anomaly detection (also called outlier detection)*\n",
    "   - Any instance that has a low affinity to all the clusters is likely to be an anomaly. For example, if you have clustered the users of your website based on their behaviour, you can detect users with unusual behaviour, such as an unusual number of requests per second. Anomaly detection is particularly useful in detecting defects in manufacturing, or for *fraud detection*.\n",
    "* *For semi-supervised learning*\n",
    "   - If you only have a few labels, you could perform clustering & propagate the labels to all the instances in the same cluster. This technique can greatly increase the number of labels available for a subsequent supervised learning algorithm, & thus improve its performance.\n",
    "* *For search engines*\n",
    "   - Some search engines let you search for images that are similar to a reference image. To build such a system, you would first apply a clustering algorithm to all the images in your database; similar images would end up in the same cluster. Then when a user provides a reference image, all you need to do is use the trained clustering model to find this image's cluster, & you can then simply return all the images from this cluster.\n",
    "* *To segment an image*\n",
    "   - By clustering pixels according to their colour, then replacing each pixel's colour with the mean colour of its cluster, it is possible to considerably reduce the number of different colors in the image. Image segmentation is used in many object detection & tracking systems, as it makes it easier to detect the contour of each object.\n",
    "  \n",
    "There is no universal definition of what a cluster is: it really depends on the context & different algorithms will capture different kinds of clusters. Some algorithms look for instance centered around a particular point, called a *centroid*. Others look for continuous regions of densely packed instances: these clusters can take on any shape. Some algorithms are hierarchical, looking for clusters of clusters. & the list goes on.\n",
    "\n",
    "In this section, we'll look at two popular clustering algorithms, K-means & DBSCAN, & explore some of their applications, such as nonlinear dimensionality reduction, semi-supervised learning, & anomaly detection.\n",
    "\n",
    "## K-Means\n",
    "\n",
    "Consider the unlabeled dataset represented in this figure, you can clearly see five blobs of instances.\n",
    "\n",
    "<img src = \"Images/Unlabeled Blobs.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "The K-means algorithm is a simple algorithm capable of clustering this kind of dataset very quickly & efficiently, often in just a few iterations. It as proposed by Stuart Lloyd at Bell Labs in 1957 as a technique for pulse-code modulation, but it was only published outside of the company in 1982. In 1965, Edward W. Forgy had published virtually the same algorithm, so K-means is sometimes referred to as Lloyd-Forgy.\n",
    "\n",
    "Let's train a K-means clusterer on this dataset. It will try to find each blob's center & assign each instance to the closest blob:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11f1076d-4b15-4c93-90df-618e1568e00b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "blob_centers = np.array([[ 0.2,  2.3],\n",
    "                         [-1.5 ,  2.3],\n",
    "                         [-2.8,  1.8],\n",
    "                         [-2.8,  2.8],\n",
    "                         [-2.8,  1.3]])\n",
    "blob_std = np.array([0.4, 0.3, 0.1, 0.1, 0.1])\n",
    "X, y = make_blobs(n_samples = 2000, centers = blob_centers,\n",
    "                  cluster_std = blob_std, random_state = 32)\n",
    "\n",
    "k = 5\n",
    "kmeans = KMeans(n_clusters = k)\n",
    "y_pred = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc1f628-97ea-40ec-bdda-8bb8d59f762c",
   "metadata": {},
   "source": [
    "Note that you have to specify the number of clusters *k* that the algorithm must find. In this example, it is pretty obvious from looking at the data that *k* should be set to 5, but it general it is not that easy.\n",
    "\n",
    "Each instance was assigned to one of the five clusters. In the context of clustering, an instance's label is the index of the cluster that this instance gets assigned to by the algorithm: this is ot to be confused with the class labels in classification (remember that clustering is an unsupervised learning task). The `KMeans` instance preserves a copy of the labels of the instances it was trained on, available via the `labels_`instance variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f79ffd01-00cd-4c85-b2d6-74955b79072f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, ..., 3, 4, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad58f6f1-50aa-421c-857c-f91257e83619",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred is kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c89fda5-c3ee-4fae-b031-cfe349cefd88",
   "metadata": {},
   "source": [
    "We can also take a look at the five centroids that the algorithm found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c4054e4-70d8-4833-b3a9-65583a0091d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03372917,  2.05637547],\n",
       "       [-2.80489665,  1.5547981 ],\n",
       "       [-2.78698665,  2.80785397],\n",
       "       [-1.50043437,  2.26794465],\n",
       "       [ 0.38990236,  2.57173401]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a95e57-8305-4861-bb23-f637586e4a2d",
   "metadata": {},
   "source": [
    "You can easily assign new instances to the cluster whose centroid is closest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fa55b31-b69d-47bc-a221-62f6a3c56f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.array([[0, 2], [3, 2], [-3, 3], [-3, 2.5]])\n",
    "kmeans.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6454db10-8e4e-41e8-8da0-4cb38bc17d41",
   "metadata": {},
   "source": [
    "If you predict the cluster's decision boundaries, you get a Voronoi tesselation, where each centroid is represented with an X.\n",
    "\n",
    "<img src = \"Images/K-Means Decision Boundaries.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "The vast majority of the instances were clearly assigned to the appropriate cluster, but a few instances were probably mislabeled (especially near the boundary between the top-left cluster & the central clsuter). Indeed, the K-means algorithm does not behave very well then the blobs have very different diameters because all it cares about when assigning an instance to a cluster is the distance to the centroid.\n",
    "\n",
    "Instead of assigning each instance to a single cluster, which is called *hard clustering*, it can be useful to give each instance a score per cluster, which is called *soft clustering*. The score can be the distance between the instance & the centroid; conversely, it can be a similarity score (or affinity), such as the gaussian radial basis function. In the `KMeans` class, the `transform()` method measures the distance from each instance to every centroid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2396bc08-1d51-4112-8d9b-d80d8cd179ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06569513, 2.8400088 , 2.9017103 , 1.52417113, 0.69202863],\n",
       "       [3.03425294, 5.82194382, 5.84310214, 4.50840369, 2.67198231],\n",
       "       [3.11274636, 1.45831199, 0.28687067, 1.66871271, 3.41684793],\n",
       "       [2.9992608 , 0.96512795, 0.37436447, 1.5174145 , 3.39066126]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.transform(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4813cb-8b39-477c-a53b-634d6c3a1c9d",
   "metadata": {},
   "source": [
    "In this example, theh first example in `X_new` is located at a distance of 1.51 from the first centroid, 2.90 from the second centroid, 0.40 from the third centroid, 2.89 from the fourth centroid, & 2.81 from the fifth centroid. If you have a high-dimensional dataset & you transform it this way, you end up with a *k*-dimensional dataset: this transformation can be a very efficient nonlinear dimensionality reduction technique.\n",
    "\n",
    "### The K-Means Algorithm\n",
    "\n",
    "So, how does the algorithm work? Well, suppose you were given the centroids. You could easily label all the instances in the dataset by assigning each of them to the cluster whose centroid is closest. Conversely, if you were given all the instance labels, you could easily locate all teh centroids by computing the mean of the instances for each cluster. But you are given neither the labels nor the centroids, so how can you proceed? Well, just start by placing the centroids randomly (e.g., by picking the *k* instances at random & using their locations as centroids). Then label the instances, update the centroids, label the instances, update the centroids, & so on until the centroids stop moving. The algorithm is guaranteed to converge in a finite number of steps (usually quite small); it will not oscillate forever.\n",
    "\n",
    "You can see the algorithm in action here: the centroids are initialised randomly (top left), then the instances are labeled (top right), then the centroids are updated (center left), the instances are relabeled (center right), & so on. As you can see, in just three iterations, the algorithm has reached a clustering that seems close to optimal.\n",
    "\n",
    "<img src = \"Images/K-Means Algorithm.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "Although the algorithm is guaranteed to converge, it may not converge to the right solution (i.e., it may converge to a local optimum): whether it does or not depends on the centroid initialisation. The below figure shows two suboptimal solutions that the algorithm can converge to if you are unlucky with the random initialisation step.\n",
    "\n",
    "<img src = \"Images/Suboptimal Solution K-Means.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "Let's look at a few ways you can mitigate this risk by improving the centroid intialisation.\n",
    "\n",
    "### Centroid Initialisation Methods\n",
    "\n",
    "If you happen to know approximately where the centroids should be (e.g., if you ran another clustering algorithm earlier), then you can set the `init` hyperparameter to a numpy array containing the list of centroids, & set `n_init` to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aae90e5-fce1-4f31-8c78-045e7880a8d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_init = np.array([[-3, 3], [-3, 2], [-3, 1], [-1, 2], [0, 2]])\n",
    "kmeans = KMeans(n_clusters = 5, init = good_init, n_init = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df3b6a9-cfa2-456e-907d-1ccf892de316",
   "metadata": {},
   "source": [
    "Another solution is to run the algorithm multiple times with different random intialisations & keep the best solution. The number of random intialisations is controlled by the `n_init` hyperparameter: by default, it is equal to 10, which means that the whole algorithm decribed earlier runs 10 times when you call `fit()`, & scikit-learn keeps the best solution. But how exactly does it know which solution is the best? It uses a performance metric. That metrics is called the model's *inertia*, which is the mean squared distance between each instance & its closest centroid. It is roughly equal to 223.3 & 237.5 on the left & right of the above figure, respectively. The `KMeans` class runs the algorithm `n_init` times & keeps the model with the lowest inertia. In this example,the model will be selected (unless we are very unlucky with `n_init` consecutive random initialisations). If you are curious, a model's inertia is accessible via the `inertia_` instance variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aecf95ce-10de-4af5-9a85-8745d23afa62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216.07129752156413"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(X)\n",
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cfa513-93f4-4974-8ed7-d797aef574e8",
   "metadata": {},
   "source": [
    "The `score()` method returns the negative inertia. Why negative? Because a predictor's `score()` method must always respect scikit-learn's \"greater is better\" rule: if a predictor is better than another, its `score()` method should return a greater score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1689a1a-88b1-40c2-a603-7927fec8c631",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-216.07129752156408"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.score(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74e58c9-e730-4af5-b719-79591e9e448c",
   "metadata": {},
   "source": [
    "An important improvement to the K-means algorithm, *K-Means++*, was proposed in a 2006 paper by David Arthur & Sergei Vassilvitskii. They introduced a smarter initialisation step that tends to select centroids that are distant from one another, & this improvement makes the K-means algorithm much less likely to converge to a suboptimal solution. They showed that the additional computation required for the smarter initialisation step is well worth it because it makes it possiblel to drastically reduce the number of times the algorithm needs to be run to find the optimal solution. here is the K-Means++ initialisation algorithm.\n",
    "\n",
    "1. Take one centroid $c^{(i)}$, chosen uniformly at random from the dataset.\n",
    "2. Take a new centroid $c^{(i)}$, choosing an instance $x^{(i)}$ with probability $D(x^{(i)})^2/\\sum^{m}_{j = 1}D(x^{(j)})^2$, where $D(x^{(i)})$ is the distance between the instance $x^{(i)}$ & the closest centroid that has already chosen. This probability distribution ensures that instances farther away from already chosen centroids are much more likely to be selected as centroids.\n",
    "3. Repeat the previous step until all *k* centroids have been chosen.\n",
    "\n",
    "The *KMeans* class uses this utilisation method by default. If you want to force it to use the original method (i.e., picking *k* instances randomly to define the intial centroids), then you can set the `init` hyperparameter to \"random\". You will rarely need to do this.\n",
    "\n",
    "### Accelerated K-means & Mini-Batch K-Means\n",
    "\n",
    "Another important improvement to the K-means algorithm was proposed in a 2003 paper by Charles Elkan. It considerably accelerates the algorithm by avoiding many unnecessary distance calculations: this is achieved by exploiting the triangle inequality (i.e., the straight line is always the shortest) & by keeping track of lower & upper bounds for distances between instances & centroids. This is the algorithm used by default by the `KMeans` class (but you can force it to use the original algorithm by setting the `algorithm` hyperparameter to `\"full\"`, although you probably never need to).\n",
    "\n",
    "Yet another important variant of the K-means algorithm was proposed in a 2010 paper by David Sculley. Instead of using the full dataset at each iteration, the algorithm is capable of using mini-batches, moving the centroids just slightly at each iteration. This speeds up the algorithm typically by a factor of 3 or 4 & makes it possible to cluster huge datasets that do not fit in memory. Scikit-learn implementes this algorithm in the `MiniBatchKMeans` class. You can just use this class like the `KMeans` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4de5afcd-5fe3-4156-85ce-b043517e7997",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MiniBatchKMeans(batch_size=2048, n_clusters=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MiniBatchKMeans<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.cluster.MiniBatchKMeans.html\">?<span>Documentation for MiniBatchKMeans</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MiniBatchKMeans(batch_size=2048, n_clusters=5)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MiniBatchKMeans(batch_size=2048, n_clusters=5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "minibatch_kmeans = MiniBatchKMeans(n_clusters = 5, batch_size = 2048)\n",
    "minibatch_kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2acd98-9c19-466e-83bb-7e6443d390c9",
   "metadata": {},
   "source": [
    "If the dataset does not fit in memory, the simplest option is to use the `memmap` class, as we did for incremental PCA. Alternatively, you can pass one mini-batch at a time to the `partial_fit()` method, but this will require much more work, since you will need to perform multiple initialisations & select the best one yourself.\n",
    "\n",
    "Although the mini-batch K-means algorithm is much faster than the regular K-means algorithm, its inertia is generally slightly worse, especially as the number of clusters increases. You can see this in the figure: the plot on the left compares the inertias of mini-batch K-means & regular K-means models trained on the previous dataset using various numbers of clusters *k*. The difference between the two curves remains fairly constant, but this difference becomes more & more significant as *k* increases, since the inertia becomes smaller & smaller. However, in the plot on the right, you can see that mini-batch K-means is much faster than regular K-means, & this difference increases with *k*.\n",
    "\n",
    "<img src = \"Images/Mini-Batch KMeans vs KMeans.png\" width = \"750\" style = \"margin:auto\"/>\n",
    "\n",
    "### Finding the Optimal Number of Clusters\n",
    "\n",
    "So far, we have set the number of clusters *k* to 5 because it was obvious by looking at the dataset that this is the correct number of clusters. But in general, it will not be so easy to know how to set *k*, & the result might be quite bad if you set it to the wrong value. For example, as you can see, setting *k* to 3 or 8 results in fairly bad models.\n",
    "\n",
    "<img src = \"Images/Bad Cluster Numbers.png\" width = \"750\" style = \"margin:auto\"/>\n",
    "\n",
    "You might be thinking that we could just pick the model with the lowest inertia, right? Unfortunately, it is not that simple. The inertia for $k = 3$ is 653.2, which is much higher than for $k = 5$ (which is 211.6), but with $k = 8$, the inertia is just 119.1. The inertia is not a good performance metric when trying to choose *k* since it keeps getting lower as we increase *k*. Indeed, the more clusters there are, the closer each instance will be to its closest centroid, & therefore the lower the inertia will be. Let's plot the inertia as a function of *k*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8574af0f-8eef-46c4-b986-844bd0828ca6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsAAAAFNCAYAAAAO6dl0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABITUlEQVR4nO3de3zOdePH8de1zcaGiw2bZTQlpwlR3ZRTJJXTTeVQQicVMqNwd6K7LO471Z3IOlAknSj1k1qyya2DxpylMprDGjU7OOz4/f3xvXfV2Mls1/e6dr2fj8f3sevwuS7v66oHbx+f7+drMwzDQERERETEQ3hZHUBERERExJlUgEVERETEo6gAi4iIiIhHUQEWEREREY+iAiwiIiIiHkUFWEREREQ8igqwiIiIiHgUH6sDuIuCggKOHDlCnTp1sNlsVscRERERkbMYhkFmZiahoaF4eZU8z6sCXE5HjhwhLCzM6hgiIiIiUobk5GSaNGlS4vMqwOVUp04dwPxC69ata3Ea93HjjbBpE8TEwLBhVqcRERGR6iwjI4OwsDBHbyuJCnA5FS57qFu3rgrweWjf3izA+/eDvjYRERFxhrKWq+okOKlSbduaP3ftsjaHiIiISCEVYKlSKsAiIiLialSApUoVFuD9++HkSWuziIiIiIAKsFSxhg2hUSPz9p491mYRERERARVgcQItgxARERFXogIsVU4FWERERFyJCrBUORVgERERcSUqwFLlCgvwzp3W5hAREREBFWBxgsIC/OuvkJlpbRYRERERFWCpcoGB0LixeXv3bmuziIiIiKgAi1NoHbCIiIi4ChVgcQoVYBEREXEVKsDiFDoRTkRERFyFCrA4hWaARURExFVYWoA3bNjAgAEDCA0NxWaz8dFHHzmey83NZdq0abRr146AgABCQ0O58847OXLkSJH3yM7OZuLEiTRo0ICAgAAGDhzIoUOHioxJS0tj1KhR2O127HY7o0aN4sSJE074hFKosAAfPgz66kVERMRKlhbgkydP0r59e+bPn3/Oc6dOnWLLli08/vjjbNmyhZUrV7Jv3z4GDhxYZFxkZCSrVq1ixYoVbNy4kaysLPr3709+fr5jzMiRI0lMTGTt2rWsXbuWxMRERo0aVeWfT/5kt0OTJuZt7QQhIiIiVrIZhmFYHQLAZrOxatUqBg8eXOKYzZs3c9VVV3Hw4EGaNm1Keno6DRs2ZOnSpQwbNgyAI0eOEBYWxpo1a7jhhhvYs2cPbdq04dtvv+Xqq68G4Ntvv6VLly7s3buXli1blitfRkYGdrud9PR06tate8Gf1xP16weffw6LFsF991mdRkRERKqb8vY1t1oDnJ6ejs1mo169egAkJCSQm5tL3759HWNCQ0OJiIhg06ZNAHzzzTfY7XZH+QX429/+ht1ud4wpTnZ2NhkZGUUOuTBaBywiIiKuwG0K8JkzZ5g+fTojR450NPqUlBR8fX2pX79+kbHBwcGkpKQ4xjRq1Oic92vUqJFjTHGio6Mda4btdjthYWGV+Gk8U+vW5s916yAuDv6ySkVERETEadyiAOfm5jJ8+HAKCgpYsGBBmeMNw8Bmsznu//V2SWPONmPGDNLT0x1HcnJyxcILACtXwqOPmrd37YJeveDii83HRURERJzJ5Qtwbm4ut912G0lJScTGxhZZzxESEkJOTg5paWlFXpOamkpwcLBjzG+//XbO+x47dswxpjh+fn7UrVu3yCEVs3Il3HILpKYWffzwYfNxlWARERFxJpcuwIXl96effuLLL78kKCioyPOdOnWiRo0axMbGOh47evQoO3fupGvXrgB06dKF9PR0vv/+e8eY7777jvT0dMcYqTr5+TBpEhR3qmXhY5GRWg4hIiIizuNj5S+elZXFzz//7LiflJREYmIigYGBhIaGcsstt7BlyxY+/fRT8vPzHWt2AwMD8fX1xW63c/fddzNlyhSCgoIIDAxk6tSptGvXjj59+gDQunVr+vXrx7333suiRYsAuO++++jfv3+5d4CQivv6azhrW+YiDAOSk81xPXs6LZaIiIh4MEsL8A8//ECvXr0c96OiogAYPXo0M2fOZPXq1QB06NChyOvWr19Pz/+1peeffx4fHx9uu+02Tp8+Te/evVmyZAne3t6O8W+//TYPPfSQY7eIgQMHFrv3sFS+o0crd5yIiIjIhXKZfYBdnfYBrpi4OPOEt7KsX68ZYBEREbkw1XIfYHE/3bqZV4ArZcMNwsLMcSIiIiLOoAIsVcrbG1580bxdUgkeONAcJyIiIuIMKsBS5YYMgQ8+gIsuKvq43W7+fOMN2LHD+blERETEM6kAi1MMGQIHDphrfZcvN38eOwY33ACnT8Ott0JmptUpRURExBNYuguEeBZv73NPdFu6FDp2hB9/hPvuM8txaeuFRURERC6UZoDFUg0bwnvvgY8PrFgBr7xidSIRERGp7lSAxXJdu8Kzz5q3IyMhIcHSOCIiIlLNqQCLS4iKgkGDICfHXA984oTViURERKS6UgEWl2CzweLFcPHFkJQEY8eal0kWERERqWwqwOIy6teH998HX1/46CN44QWrE4mIiEh1pAIsLqVzZ3j+efP2I4/Apk3W5hEREZHqRwVYXM4DD8CwYZCXZ/48ftzqRCIiIlKdqACLy7HZ4NVX4bLL4NAhGDUKCgqsTiUiIiLVhQqwuKQ6dcz1wDVrwtq1f26TJiIiInKhVIDFZV1+OSxYYN5+/HHz8skiIiIiF0oFWFza2LEwZoy5BGLECEhJsTqRiIiIuDsVYHF5L78MERHw229mCc7PtzqRiIiIuDMVYHF5/v7meuDatSEuDmbOtDqRiIiIuDMVYHELrVpBTIx5++mnzRPjRERERCpCBVjcxogR5h7BAHfcAcnJ1uYRERER96QCLG5l3jy44gr4/XfzIhm5uVYnEhEREXejAixupWZNcz2w3Q7ffAMzZlidSERERNyNCrC4nebNYfFi8/Zzz8HHH1ubR0RERNyLCrC4pb//HaKizNujR8P+/dbmEREREfehAixu69lnoUsXSE+HW2+FM2esTiQiIiLuQAVY3FaNGvDuuxAUBFu2wJQpVicSERERd6ACLG4tLAyWLjVvL1gAK1ZYm0dERERcnwqwuL0bb4RHHzVv33sv/PijtXlERETEtakAS7Uwcyb07AlZWXDLLXDqlNWJRERExFWpAEu14OMDy5dDcDDs3AkTJlidSERERFyVCrBUG40bwzvvgJeXuU9w4V7BIiIiIn9laQHesGEDAwYMIDQ0FJvNxkcffVTkecMwmDlzJqGhodSqVYuePXuya9euImOys7OZOHEiDRo0ICAggIEDB3Lo0KEiY9LS0hg1ahR2ux273c6oUaM4ceJEFX86sUKvXjBrlnl7/HjYscPaPCIiIuJ6LC3AJ0+epH379syfP7/Y5+fOncu8efOYP38+mzdvJiQkhOuvv57MzEzHmMjISFatWsWKFSvYuHEjWVlZ9O/fn/z8fMeYkSNHkpiYyNq1a1m7di2JiYmMGjWqyj+fWOMf/4AbboDTp839gf/yv4uIiIgINsMwDKtDANhsNlatWsXgwYMBc/Y3NDSUyMhIpk2bBpizvcHBwcyZM4dx48aRnp5Ow4YNWbp0KcOGDQPgyJEjhIWFsWbNGm644Qb27NlDmzZt+Pbbb7n66qsB+Pbbb+nSpQt79+6lZcuWxebJzs4mOzvbcT8jI4OwsDDS09OpW7duFX4TUhmOH4cOHeDwYRg+3FwfbLNZnUpERESqUkZGBna7vcy+5rJrgJOSkkhJSaFv376Ox/z8/OjRowebNm0CICEhgdzc3CJjQkNDiYiIcIz55ptvsNvtjvIL8Le//Q273e4YU5zo6GjHkgm73U5YWFhlf0SpQg0awHvvmSfHrVgBr7xidSIRERFxFS5bgFNSUgAIDg4u8nhwcLDjuZSUFHx9falfv36pYxo1anTO+zdq1MgxpjgzZswgPT3dcSQnJ1/Q5xHn69rVvFwyQGQkJCRYGkdERERchMsW4EK2s/7d2jCMcx4729ljihtf1vv4+flRt27dIoe4n6goGDQIcnLM9cA691FERERctgCHhIQAnDNLm5qa6pgVDgkJIScnh7S0tFLH/Pbbb+e8/7Fjx86ZXZbqx2Yzt0MLD4ekJBg7Flxj1buIiIhYxWULcHh4OCEhIcTGxjoey8nJIT4+nq5duwLQqVMnatSoUWTM0aNH2blzp2NMly5dSE9P5/vvv3eM+e6770hPT3eMkeqtfn1zPbCvL3z0ETz/vNWJRERExEo+Vv7iWVlZ/Pzzz477SUlJJCYmEhgYSNOmTYmMjGT27Nm0aNGCFi1aMHv2bPz9/Rk5ciQAdrudu+++mylTphAUFERgYCBTp06lXbt29OnTB4DWrVvTr18/7r33XhYtWgTAfffdR//+/UvcAUKqn86dzeI7fjxMmwZ/+5u5RlhEREQ8j6XboMXFxdGrV69zHh89ejRLlizBMAxmzZrFokWLSEtL4+qrr+bll18mIiLCMfbMmTM8/PDDLF++nNOnT9O7d28WLFhQZNeGP/74g4ceeojVq1cDMHDgQObPn0+9evXKnbW822qI6zIMGDnS3BWiSRPYutXcLUJERESqh/L2NZfZB9jVqQBXD5mZ5mzwvn3mxTLWrDEvnSwiIiLuz+33ARapCnXqwAcfQM2a8PnnEB1tdSIRERFxNhVg8Tjt2sGCBebtJ56A9eutzSMiIiLOpQIsHmnsWBgzBgoKYMQIKOWaKCIiIlLNqACLx3r5ZYiIgN9+M0twfr7ViURERMQZVIDFY/n7m+uBa9eGuDh48kmrE4mIiIgzqACLR2vZEmJizNvPPAOffWZtHhEREal6KsDi8UaMgAceMG+PGgXJydbmERERkaqlAiyCeZW4Tp3g999h2DDIzbU6kYiIiFQVFWARwM8P3nsP7Hb45huYMcPqRCIiIlJVVIBF/qd5c1iyxLz93HPw0UdWphEREZGqogIs8heDB0NUlHl7zBjYv9/KNCIiIlIVVIBFzvLss9ClC6Snw623wpkzVicSERGRyqQCLHKWGjXg3XchKAi2bIEpU6xOJCIiIpVJBVikGGFhsGyZeXvBAlixwto8IiIiUnlUgEVK0K8fPPqoefuee2DvXmvziIiISOVQARYpxcyZ0LMnnDxprgc+dcrqRCIiInKhVIBFSuHjA++8A8HBsHMnTJhgdSIRERG5UCrAImUICTFLsJcXLF5sHiIiIuK+VIBFyqFXL3jqKfP2+PGwY4e1eURERKTiVIBFymnGDLjhBjh9Gm65BTIzrU4kIiIiFaECLFJOXl7m1mhNmsC+fXDffWAYVqcSERGR86UCLHIeGjQwL5Lh42PuDfzKK1YnEhERkfOlAixynrp2hTlzzNuRkfDDD5bGERERkfOkAixSAZMnw6BBkJNj7g+clmZ1IhERESkvFWCRCrDZYMkSCA+HAwdg7FitBxYREXEXKsAiFVSvHrz/Pvj6wscfw/PPW51IREREykMFWOQCdOoEL7xg3p42DTZtsjSOiIiIlIMKsMgFuv9+GD4c8vJg2DA4ftzqRCIiIlIaFWCRC2SzQUwMXHYZHDoEd9wBBQVWpxIREZGSqACLVII6deCDD6BWLfj8c4iOtjqRiIiIlMSlC3BeXh6PPfYY4eHh1KpVi+bNm/PUU09R8JfpNcMwmDlzJqGhodSqVYuePXuya9euIu+TnZ3NxIkTadCgAQEBAQwcOJBDhw45++NINdeuHSxYYN5+4glYv97aPCIiIlI8ly7Ac+bM4ZVXXmH+/Pns2bOHuXPn8q9//YuXXnrJMWbu3LnMmzeP+fPns3nzZkJCQrj++uvJzMx0jImMjGTVqlWsWLGCjRs3kpWVRf/+/cnPz7fiY0k1NmaMuSVaQQGMGAFHj1qdSERERM5mMwzX3b20f//+BAcH8/rrrzseGzp0KP7+/ixduhTDMAgNDSUyMpJp06YB5mxvcHAwc+bMYdy4caSnp9OwYUOWLl3KsGHDADhy5AhhYWGsWbOGG264oVxZMjIysNvtpKenU7du3cr/sFJtnDoFV18NO3dCjx7w5ZfmpZNFRESkapW3r7n0DPC1117LunXr2LdvHwDbtm1j48aN3HTTTQAkJSWRkpJC3759Ha/x8/OjR48ebPrfflQJCQnk5uYWGRMaGkpERIRjTHGys7PJyMgocoiUh7+/uR64dm2Ij4eZM61OJCIiIn/l0gV42rRpjBgxglatWlGjRg06duxIZGQkI0aMACAlJQWA4ODgIq8LDg52PJeSkoKvry/169cvcUxxoqOjsdvtjiMsLKwyP5pUcy1bwmuvmbefeQY++8zaPCIiIvInly7A7777LsuWLWP58uVs2bKFN998k3//+9+8+eabRcbZbLYi9w3DOOexs5U1ZsaMGaSnpzuO5OTkin8Q8UjDhsGDD5q3R40C/S8kIiLiGly6AD/88MNMnz6d4cOH065dO0aNGsXkyZOJ/t8eUyEhIQDnzOSmpqY6ZoVDQkLIyckhLS2txDHF8fPzo27dukUOkfM1b555tbjffzcLcW6u1YlERETEpQvwqVOn8PIqGtHb29uxDVp4eDghISHExsY6ns/JySE+Pp6uXbsC0KlTJ2rUqFFkzNGjR9m5c6djjEhV8fOD994Dux2++QamT7c6kYiIiLj0uekDBgzgmWeeoWnTprRt25atW7cyb9487rrrLsBc+hAZGcns2bNp0aIFLVq0YPbs2fj7+zNy5EgA7HY7d999N1OmTCEoKIjAwECmTp1Ku3bt6NOnj5UfTzxE8+bw5psweLA5I3zttfD3v1udSkRExHO59DZomZmZPP7446xatYrU1FRCQ0MZMWIETzzxBL6+voC5lnfWrFksWrSItLQ0rr76al5++WUiIiIc73PmzBkefvhhli9fzunTp+nduzcLFiw4rxPbtA2aXKipU+G558zZ4C1bzGIsIiIilae8fc2lC7ArUQGWC5Wba+4L/M03cMUV8N//Qs2aVqcSERGpPqrFPsAi1UmNGvDuuxAUZM4AR0VZnUhERMQzqQCLOFFYGCxbBjYbLFwI77xjdSIRERHPowIs4mT9+sGjj5q3770X9u61No+IiIinUQEWscDMmdCrF5w8CbfeCqdOWZ1IRETEc6gAi1jA2xuWL4fgYNi5E8aPtzqRiIiI51ABFrFISAisWAFeXrBkCSxebHUiERERz1DhC2Fs3ryZ999/n19//ZWcnJwiz61cufKCg4l4gp494Z//NNcEP/igednkyy+3OpWIiEj1VqEZ4BUrVnDNNdewe/duVq1aRW5uLrt37+arr77CbrdXdkaRam36dPPEuDNnzPXAmZlWJxIREaneKlSAZ8+ezfPPP8+nn36Kr68vL774Inv27OG2226jadOmlZ1RpFrz8oKlS6FJE9i3D+67D3R5GhERkapToQL8yy+/cPPNNwPg5+fHyZMnsdlsTJ48mZiYmEoNKOIJGjQwL5Lh42OuC1640OpEIiIi1VeFCnBgYCCZ//t32osuuoidO3cCcOLECU5pPyeRCunaFebMMW9Pngw//GBtHhFPYLPZ+OijjwA4cOAANpuNxMRESzOJSNWrUAHu1q0bsbGxANx2221MmjSJe++9lxEjRtC7d+9KDSjiSSZPhsGDISfHXA+clmZ1IhH3NmbMGGw22zlHv379rI4mIhaq0C4Q8+fP58yZMwDMmDGDGjVqsHHjRoYMGcLjjz9eqQFFPInNZm6Htm0bJCXB2LGwapX5uIhUTL9+/Vh81j6Dfn5+FqUREVdQ4SUQoaGh5ht4efHII4+wevVq5s2bR/369Ss1oIinqVcP3n8ffH3h449h3jyrE4m4Nz8/P0JCQoocpf1ZtXfvXrp27UrNmjVp27YtcXFxRZ6Pj4/nqquuws/Pj8aNGzN9+nTy8vIA+OSTT6hXrx4FBQUAJCYmYrPZePjhhx2vHzduHCNGjKj8Dyoi5VbuApyRkVHkdmmHiFyYTp3ghRfM29OmwX//a2kcEY/y8MMPM2XKFLZu3UrXrl0ZOHAgv//+OwCHDx/mpptu4sorr2Tbtm0sXLiQ119/naeffhqA7t27k5mZydatWwGzLDdo0ID4+HjH+8fFxdGjRw/nfzARcSh3Aa5fvz6pqakA1KtXj/r1659zFD4uIhfu/vthxAjIz4dhw+DYMasTibinTz/9lNq1axc5/vnPf5Y4fsKECQwdOpTWrVuzcOFC7HY7r7/+OgALFiwgLCyM+fPn06pVKwYPHsysWbN47rnnKCgowG6306FDB8escVxcHJMnT2bbtm1kZmaSkpLCvn376NmzpxM+uYiUpNxrgL/66isCAwMBWL9+fZUFEhGTzQaLFsGWLfDjjzBqFKxZY+4bLCLl16tXLxaetbdg4Z9nxenSpYvjto+PD507d2bPnj0A7Nmzhy5dumD7y8L8a665hqysLA4dOkTTpk3p2bMncXFxREVF8fXXX/P000/z4YcfsnHjRk6cOEFwcDCtWrWq5E8pIuej3AX4r/9cEx4eTlhYWJHfAAAMwyA5Obny0ol4uDp1zPXAV18Nn38O0dHmZZNFpPwCAgK49NJLL+g9Cv+8Mwyj2D/7/jqmZ8+evP7662zbtg0vLy/atGlDjx49iI+PJy0tTcsfRFxAheaSwsPDOVbMv8f+8ccfhIeHX3AoEflTu3awYIF5+4knQP8AI1K1vv32W8ftvLw8EhISHDO2bdq0YdOmTY7SC7Bp0ybq1KnDRRddBPy5DviFF16gR48e2Gw2evToQVxcnNb/iriIChXg4v4GDJCVlUXNmjUvOJSIFDVmjLklWkGBuS740CGIi4N33jF/5udbHFDEhWVnZ5OSklLkOH78eInjX375ZVatWsXevXsZP348aWlp3HXXXQA8+OCDJCcnM3HiRPbu3cvHH3/Mk08+SVRUFF7/W59UuA542bJljrW+3bt3Z8uWLVr/K+Iizmsf4KioKMD8Z57HH38cf39/x3P5+fl89913dOjQoVIDiohp/nzz6nA7dsAll5gXyyjUpAm8+CIMGWJdPhFXtXbtWho3blzksZYtW7J3795ixz/77LPMmTOHrVu3cskll/Dxxx/ToEEDwLz66Zo1a3j44Ydp3749gYGB3H333Tz22GNF3qNXr15s2bLFUXbr169PmzZtOHLkCK1bt678Dyki58Vm/PXfccrQq1cvwNzWpUuXLvj6+jqe8/X15eKLL2bq1Km0aNGi8pNaLCMjA7vdTnp6OnXr1rU6jniol16Chx469/HCf5D54AOVYBER8Vzl7WvnVYALjRkzhpdeeok6depcUEh3ogIsVsvPh4svNpc/FMdmM2eCk5LA29up0URERFxCefvaea8BzsvLY9myZRw8ePCCAorI+fn665LLL4BhQHKyOU5ERERKdt4F2MfHh2bNmpGvs25EnOro0codJyIi4qkqtAvEY489xowZM/jjjz8qO4+IlOCsc3gueJyIiIinqtAa4I4dO/Lzzz+Tm5tLs2bNCAgIKPL8li1bKi2gq9AaYLFa4Rrgw4fN5Q7FadjQnAHWGmAREfFE5e1r57UNWqHBgwdXNJeIVJC3t7nV2S23mCe8FVeC09Lg009h0CDn5xMREXEXFZoB9kSaARZXsXIlTJpU9IS4Jk3M49tvzaK8bBkMH25dRhEREStU2S4QhU6cOMFrr71WZC3wli1bOHz4cEXfUkTKYcgQOHDAvCTy8uXmzwMHzN0f7rjDXCoxciS88YbVSUVERFxThZZAbN++nT59+mC32zlw4AD33nsvgYGBrFq1ioMHD/LWW29Vdk4R+QtvbyjuaqpvvgkBAbBoEdx9N5w6BRMmOD2eyAXJycnhhRdeoGXLlgzSeh4RqQIVmgGOiopizJgx/PTTT9SsWdPx+I033siGDRsqLRzA4cOHueOOOwgKCsLf358OHTqQkJDgeN4wDGbOnEloaCi1atWiZ8+e7Nq1q8h7ZGdnM3HiRBo0aEBAQAADBw7kUGkbqoq4KS8vWLgQJk8270+cCHPmWJtJ5Hxs376dK664gmnTpjF8+HB++eUXqyOJSDVUoQK8efNmxo0bd87jF110ESkpKRccqlBaWhrXXHMNNWrU4LPPPmP37t0899xz1KtXzzFm7ty5zJs3j/nz57N582ZCQkK4/vrryczMdIyJjIxk1apVrFixgo0bN5KVlUX//v21l7FUSzYbPPccPP64eX/6dPO2VvuLK8vLy2P27Nl06tSJvXv3Oh6788479Xu1iFQ+owIaNWpkbNmyxTAMw6hdu7bxyy+/GIZhGJ9//rnRpEmTirxlsaZNm2Zce+21JT5fUFBghISEGM8++6zjsTNnzhh2u9145ZVXDMMwjBMnThg1atQwVqxY4Rhz+PBhw8vLy1i7dm2J733mzBkjPT3dcSQnJxuAkZ6eXgmfTMQ5nn3WMMzqaxiTJxtGQYHViUTOtWfPHuOKK64wbDabAZxzPPfcc1ZHFBE3kZ6eXq6+VqEZ4EGDBvHUU0+Rm5sLgM1m49dff2X69OkMHTq0cpo5sHr1ajp37sytt95Ko0aN6NixI6+++qrj+aSkJFJSUujbt6/jMT8/P3r06MGmTZsASEhIIDc3t8iY0NBQIiIiHGOKEx0djd1udxxhYWGV9rlEnGXaNHjpJfP288/D/fdDQYG1mUQKFRQU8Pzzz9O+fXu2bduGUcI/U0yfPp09e/Y4OZ2IVGcVKsD//ve/OXbsGI0aNeL06dP06NGDSy+9lDp16vDMM89UWrj9+/ezcOFCWrRoweeff87999/PQw895DjJrnC5RXBwcJHXBQcHO55LSUnB19eX+vXrlzimODNmzCA9Pd1xJCcnV9rnEnGmCRPMHSG8vCAmBkaPhrw8q1OJp/vll1/o1q0bUVFR5OTklLrMITc3l6efftqJ6USkuqvQLhB169Zl48aNfPXVV2zZsoWCggKuuOIK+vTpU6nhCgoK6Ny5M7NnzwbMK9Dt2rWLhQsXcueddzrG2Wy2Iq8zDOOcx85W1hg/Pz/8/PwuIL2I6xg7Fvz9zW3Sli0zd4d45x3w9bU6mXgawzBYtGgRkydPdvwrYmlsNhuXXXYZ06dPd0I6EfEUFSrAha677jquu+66yspyjsaNG9OmTZsij7Vu3ZoPP/wQgJCQEMCc5W3cuLFjTGpqqmNWOCQkhJycHNLS0orMAqemptK1a9cqyy7iaoYNg1q14NZbzYtpDB4MH35oPibiDMnJyYwZM4avvvqqzLHe3t4UFBTwyCOPMGvWLE1IiEilqnABXrduHevWrSM1NZWCsxYVvlFJO/Bfc801/Pjjj0Ue27dvH82aNQMgPDyckJAQYmNj6dixI2DuHxkfH8+c/+391KlTJ2rUqEFsbCy33XYbAEePHmXnzp3MnTu3UnKKuIuBA/+8VPJnn8FNN8Hq1VCnjtXJpDozDIM333yTCRMmkJ2dXeZ4Ly8vmjVrxttvv83f/vY3JyQUEU9ToTXAs2bNom/fvqxbt47jx4+TlpZW5KgskydP5ttvv2X27Nn8/PPPLF++nJiYGMaPHw+Y/zQWGRnJ7NmzWbVqFTt37mTMmDH4+/szcuRIAOx2O3fffTdTpkxh3bp1bN26lTvuuIN27dpV+pINEXdw/fXw+edm6Y2Lg7594cQJq1NJdZWSksKAAQMYO3YsJ0+eJK+UBeheXuYfSRMmTGDHjh0qvyJSdSqyxURISIjx1ltvVeSl5+2TTz4xIiIiDD8/P6NVq1ZGTExMkecLCgqMJ5980ggJCTH8/PyM7t27Gzt27Cgy5vTp08aECROMwMBAo1atWkb//v2NX3/99bxylHdbDRF38d13hlG/vrlFWocOhpGaanUiqW5WrFhh2O12w9vbu9jtzf56eHl5GU2aNDHWr19vdWwRcWPl7Ws2wzj/7fGDgoL4/vvvueSSSyqvibu4jIwM7HY76enp1K1b1+o4IpVi+3ZzRjg1Fdq0gdhYCA21OpW4u+PHj/PAAw/wwQcfYLPZStzeDMxZ34KCAu69916ee+456mg9johcgPL2tQotgbjnnntYvnx5hcOJiGu4/HKIj4eLLoLdu6F7dzh40OpU4s5Wr15Ny5YtWbVqFUCp5dfb25uGDRvy2WefERMTo/IrIk5ToZPgzpw5Q0xMDF9++SWXX345NWrUKPL8vHnzKiWciFS9Vq3g66+hd2/45Rfo1g3WrYMWLaxOJu7kxIkTPPTQQyxdurTMWd/C50eMGMFLL71U5PL2IiLOUKECvH37djp06ADAzp07KzOPiFggPBw2bIA+feDHH82Z4C+/hLZtrU4m7uCLL77gzjvv5Pjx40DZs752u5033niDQYMGOSuiiEgRFVoD7Im0Blg8wW+/mbtCbN8OQUHwxRdwxRVWpxJXlZmZydSpU4mJiXGs5S1J4azvkCFDWLRoEQ0aNHBiUhHxFOXta+c1AzxkyJAyx9hsNseFKkTEvQQHw/r10K8fbN4MvXqZ+wXrmjFytvj4eEaNGsXhw4cBSi2/3t7e1K5dm1deeYVhw4aVeaVOEZGqdl4F2G63V1UOEXERgYHm8of+/c21wX37mhfLqMKLPoobOX36NDNmzOA///kPNput1OJb6IYbbuC1114rcsVOEREraQlEOWkJhHiaU6fg7383l0H4+ZmXTb75ZqtTiZW+++47br/9dpKSksosvt7e3tSsWZOXXnqJMWPGaNZXRJyiSrdBE5Hqz9/fnPkdNAiys80y/MEHVqcSK2RnZzNjxgy6dOnCgQMHyjXr2717d3bv3s3YsWNVfkXE5agAi0iJ/Pzg/fdh+HDIzYVhw+Ctt6xOJc60detWOnbsyJw5czAMg/z8/BLH+vj4ULNmTRYsWMC6deto2rSpE5OKiJSfCrCIlKpGDVi2DO66CwoKYPRoeOUVq1NJVcvNzeWpp57iyiuvZN++faVubVboyiuvZOfOnTzwwAOa9RURl1ahfYBFxLN4e8Orr0JAALz0EjzwgLlGOCrK6mRSFXbt2sXtt9/O9u3byyy+3t7eeHl58eyzzzJp0iS8vb2dlFJEpOI0Aywi5eLlBS++CNOnm/enTIGnngKdRlt95Ofn869//YsOHTqwc+fOMsuvzWbj8ssvZ9u2bURFRan8iojbUAEWkXKz2SA6Gp5+2rz/5JNmIVYJdn8//fQT11xzDY888gh5eXmlrvX19vbGx8eHf/7zn3z//fe0bt3aiUlFRC6clkCIyHl79FFzOcTkyTB3Lpw8Cf/5jzlLLO6loKCABQsWMHXq1FJLbyGbzUbLli1Zvnw57du3d0JCEZHKpz+uRKRCIiNh0SJzVvjll+Huu6Ec/UlcyMGDB7nuuuuYOHEi2dnZ5OXllTi2cK3vjBkz2Lp1q8qviLg1zQCLSIXdd5+5X/Do0bBkiXli3LJl5s4R4roMw+CNN97goYceIjs7u8zxNpuN8PBw3n77ba666ionJBQRqVqaARaRC3LHHfDee2bpfe89GDoUzpyxOpWU5MiRI9x0003cc889nDp1qtRlD15eXthsNiIjI9m+fbvKr4hUGyrAInLBhg6Fjz6CmjXhk09g4EBzXbC4DsMwWL58Oa1btyY2NrbM8V5eXjRp0oT4+HjmzZtHrVq1nJBSRMQ5VIBFpFLcdBOsWWOeHBcbC/36QUaG1akEIDU1lSFDhnD77beTmZlZ5qwvwLhx49i1axfdunVzVkwREadRARaRStOrl1l+7XbYuBF694Y//rA6lWdbuXIlrVq14pNPPgEodW9fb29vgoODiY2NZcGCBdSuXdtZMUVEnEoFWEQqVZcusH49NGgAP/wAPXvCb79ZncrzpKWlMXLkSIYOHcqJEydKnfUtvGzxHXfcwZ49e+jTp4+zYoqIWEIFWEQqXceOEB8PjRvDjh3QvTscOmR1Ks/x2Wef0apVK9577z2g7FnfoKAgPvnkE5YsWYLdbndWTBERy6gAi0iVaNMGNmyApk1h3z7o1g3277c6VfWWkZHBPffcw0033cTx48fLNes7dOhQ9u7dS//+/Z0VU0TEcirAIlJlLr0Uvv7a/HnggFmC9+61OlX19NVXX9G6dWuWLFkCmFd4K4m3tzd2u5333nuPd999l6CgICelFBFxDSrAIlKlmjY1Z4LbtoUjR8zlENu2WZ2q+jh16hQTJ06kd+/epKSklOtyxjfddBN79+7l1ltvdUJCERHXowIsIlWucWOIi4MrroBjx8wT4777zupU7m/Tpk1ERESwYMECoOxZ39q1a/PWW2/x8ccfExwc7KyYIiIuRwVYRJyiQQP46ivo2hVOnIA+fcyZYTl/Z86c4ZFHHuHaa6/l119/LbX4FurVqxd79uxh1KhRjvW/IiKeSgVYRJzGbofPP4frroOsLPNiGZ9/bnUq95KQkED79u157rnnMAyj1CUP3t7e1KpVi0WLFvHFF1/QpEkTJyYVEXFdKsAi4lS1a8Onn8LNN8Pp0+Zlkz/6yOpUri83N5eZM2dy1VVX8csvv5Rr1rdLly7s2rWL++67T7O+IiJ/oQIsIk5XqxasXAm33AI5OebPd96xOpXr2rFjB506deKpp56ioKCgzFlfX19fXnjhBeLj4wkPD3diUhER9+BWBTg6OhqbzUZkZKTjMcMwmDlzJqGhodSqVYuePXuya9euIq/Lzs5m4sSJNGjQgICAAAYOHMgh7covYilfX7P0jhoF+flw++3w+utWp3It+fn5zJkzhyuuuILdu3eXekELMPf2veKKK9i+fTuTJk3Cy8utfosXEXEat/ndcfPmzcTExHD55ZcXeXzu3LnMmzeP+fPns3nzZkJCQrj++uvJzMx0jImMjGTVqlWsWLGCjRs3kpWVRf/+/cu1XZCIVB0fH1iyBO6/HwwD7rkH/vMfq1O5hn379tGlSxemT59OXl5embO+Pj4+zJ49m02bNtGyZUsnJhURcT9uUYCzsrK4/fbbefXVV6lfv77jccMweOGFF3j00UcZMmQIERERvPnmm5w6dYrly5cDkJ6ezuuvv85zzz1Hnz596NixI8uWLWPHjh18+eWXVn0kEfkfLy9YsACiosz7kybBs89am8lKBQUFvPjii1x++eVs3bq1zPE2m402bdqwdetWpk+fjo+PjxNSioi4N7cowOPHj+fmm2+mT58+RR5PSkoiJSWFvn37Oh7z8/OjR48ebNq0CTDPmM7NzS0yJjQ0lIiICMeY4mRnZ5ORkVHkEJGqYbPBv/8NTzxh3p8xAx57zJwV9iRJSUn07NmTyMhIsrOzycvLK3Gst7c3Xl5ePPHEEyQkJBAREeHEpCIi7s3lpwpWrFjBli1b2Lx58znPpaSkAJyzoXtwcDAHDx50jPH19S0yc1w4pvD1xYmOjmbWrFkXGl9Eyslmg1mzICAApk2DZ56Bkydh3jzzuerMMAxeffVVIiMjyc3NLXO8l5cXl156KW+//TadOnVyQkIRkerFpWeAk5OTmTRpEsuWLaNmzZoljjt7ex/DMMrc8qesMTNmzCA9Pd1xJCcnn194EamQRx6B+fPN2y+8AOPGmSfJVVeHDh2ib9++jBs3jtOnT5c562uz2ZgyZQqJiYkqvyIiFeTSBTghIYHU1FQ6deqEj48PPj4+xMfH85///AcfHx/HzO/ZM7mpqamO50JCQsjJySEtLa3EMcXx8/Ojbt26RQ4RcY7x42HxYnN98KuvwujRUEovdDnHjh2jW7duxMfHlzjGMAyWLl1K69atiYuLK/M9vby8CAsLY+PGjcydO7fUSQERESmdSxfg3r17s2PHDhITEx1H586duf3220lMTKR58+aEhIQQGxvreE1OTg7x8fF07doVgE6dOlGjRo0iY44ePcrOnTsdY0TE9YwZA8uXmztFvP023HYbZGdbnap8nnzySTZu3MjIkSNJT08/5/nffvuNQYMGceedd5KVlVXqrG/hVmYPPvigft8SEakkLr0GuE6dOuec2BEQEEBQUJDj8cjISGbPnk2LFi1o0aIFs2fPxt/fn5EjRwJgt9u5++67mTJlCkFBQQQGBjJ16lTatWt3zkl1IuJahg0Df3/zQhmrVsHgweYFNGrVsjpZyfbs2cOiRYsAs+hOnjyZN954w/H8Bx98wL333ltkq8aSeHt7ExISwltvvcV1111XZZlFRDyNS88Al8cjjzxCZGQkDz74IJ07d+bw4cN88cUX1KlTxzHm+eefZ/Dgwdx2221cc801+Pv788knn+Dt7W1hchEpjwED4P/+zyzCa9fCTTdBObqjZaKiohznF+Tn57N48WL+7//+j99//51hw4Zx6623kp6eXuq+voWvHzt2LLt371b5FRGpZDajrEsLCQAZGRnY7XbS09O1HljEAhs3/ll+//Y3WLMGztrcxXJffvkl119/fZHHvLy8qF+/PjabjbS0tDIvwOPt7U1QUBBLlizhxhtvrMq4IiLVTnn7mtvPAIuIZ7j2WvjqKwgMhG+/heuug2PHrE71p/z8fCZNmnTOvywVFBSQlpbGH3/8Ua5Z32HDhrF3716VXxGRKqQCLCJuo3NniIuDRo0gMRF69IAjR6xOZVqyZAm7d+8utuQWFBRQUFBQ4mu9vb2pV68eK1eu5O233z5n33IREalcKsAi4lbatYOvv4YmTWDPHujWDQ4csDZTVlYW06dPP+/XFc76Dhw4kB9//JG///3vlR1NRESKoQIsIm7nssvMEty8OezfD927w7591uWZO3cuf/zxx3m9xtvbmzp16rB8+XI+/PBDGjZsWEXpRETkbCrAIuKWLr4YNmyAVq0gOdkswTt3Oj/HoUOHmDt3bqlLHIrTp08f9uzZw4gRI8q8cqWIiFQuFWARcVsXXQTx8dC+Pfz2m7kmOCHBuRn+8Y9/lHohi+L4+fnx2muvERoaWkWpRESkNCrAIuLWGjUyd4e46ir44w9zd4j//tc5v3ZCQgJLly4tc2uzs+Xl5XHXXXehXShFRKyhAiwibi8wEGJjzWUQGRnQty+sW1e1v6ZhGERGRlbogjr5+fnExsby2muvVUEyEREpiwqwiFQLdevCZ5+Z5ffUKbj5ZvMKclXl448/ZuPGjec9+/tXkyZN4oDVW1iIiHggFWARqTb8/WH1ahg0CLKzYfBgeP/9yv91cnJyiIqKwsurYr+F+vj44O3tzenTp5k/f34lpxMRkbL4WB1ARKQy+fmZpXf0aHjnHRg+HE6fhjvvrLxfY+HChRw4cKDENbw2mw0fHx/y8vIcY2w2GyEhIVx66aW0aNGC5s2b07x5c/r161d5wUREpFxUgEWk2qlRA5YuNWeEX3/dLMMnT8IDD1z4e588eZInnngCwzAcJbeQv78/4eHhXHbZZVxyySWOktu8eXOaNWuGr6/vhQcQEZELpgIsItWStzfExEBAAPznP/Dgg+ba4ClTLvy9b775Zvz9/c8puYGBgdrTV0TEDagAi0i15eUFL7xgluDoaJg6FbKy4IknoKI9NSAggOXLl1dqThERcS6dBCci1ZrNBrNnwzPPmPdnzoRp00Bb8IqIeC7NAIuIR/jHP8w1wZMnw7/+Za4Jfuklswh//TUcPQqNG0O3bubyCRERqb5UgEXEY0RGmsshxo2DBQtg9274+Wc4dOjPMU2awIsvwpAhlsUUEZEqpiUQIuJR7r3X3CHCywvi4oqWX4DDh+GWW2DlSkviiYiIE6gAi4jHGT4c6tcv/rnCtcGRkXABF3kTEREXpiUQIuJxvv4afv+95OcNA5KTYcIE6N4dLrroz6NmTeflFBGRqqECLCIe5+jR8o175RXz+KvAwKKF+KKLzHXDf70fFFTxbdZERKTqqQCLiMdp3Lh843r3hrw8c13w4cPmJZX/+MM8duwo+XV+fhAaWnpRDg0FXRhORMQaKsAi4nG6dTPL6OHDxe8HbLOZz3/++Z9bohkGnDhhvubQoT9L8dnHsWOQnQ1JSeZRmoYNzy3JZ5flevU0mywiUtlUgEXE43h7m1ud3XKLWS7/WoILy+YLLxTdD9hmM0+cq18fIiJKfu/sbHOJRWEhLqks5+SYZfnYMUhMLPn9atUquSQXFuWQEKhR40K+ERERz2IzDF0PqTwyMjKw2+2kp6dTt25dq+OISCVYuRImTSq6FVpYmFl+q3IfYMMwT8I7uxSfXZb/+KN872ezQXBw2UW5Kn/rys/XBUVExHrl7WsqwOWkAixSPblycTt9Go4cKX4GubAsHzlirlMuj9q1Sy/JF11kziaf7+cv7i8SuqCIiFhBBbiSqQCLiCsqKDCXUZS0JrmwLKenl+/9vL3NElxWUa5d2xy/cqW5lOTsP0kKl5J88IFKsIg4jwpwJVMBFhF3dvJk6SX58GFzFry8F/+oW9cswvv3m+uei2OzmWMOHHCdWXURqd7K29d0EpyIiAcICIDLLjOPkuTnw2+/lV2UMzMhI8M8SmMY5uyz3W7OKgcFlf/w99fuFyJSdTQDXE6aARYRMWVmmkX4rbcgOrpqfg0/v/MrzEFB5g4dmmkW8WyaARYRkSpRpw60agV9+5avAC9ZApdcYu58UZ4jN9dcVnHkiHmUl81m7pt8vsXZ37+i30TVcOUTM0WqC5eeAY6OjmblypXs3buXWrVq0bVrV+bMmUPLli0dYwzDYNasWcTExJCWlsbVV1/Nyy+/TNu2bR1jsrOzmTp1Ku+88w6nT5+md+/eLFiwgCZNmpQ7i2aARUSKys+Hiy8u+4IiSUnlL3CGAVlZ5S/LhUdZyzFKU7NmxWabvbwq/muWRDtqiFyYanESXL9+/Rg+fDhXXnkleXl5PProo+zYsYPdu3cTEBAAwJw5c3jmmWdYsmQJl112GU8//TQbNmzgxx9/pE6dOgA88MADfPLJJyxZsoSgoCCmTJnCH3/8QUJCAt7l/F1ZBVhE5FyFu0BA8RcUcdYuELm55r7J51ucy7uF3NkKL4xyvsW5Vq2S31M7aohcuGpRgM927NgxGjVqRHx8PN27d8cwDEJDQ4mMjGTatGmAOdsbHBzMnDlzGDduHOnp6TRs2JClS5cybNgwAI4cOUJYWBhr1qzhhhtuKPbXys7OJvsvpzZnZGQQFhamAiwicharLihyoQzDXM98vqU5M7Piv2atWiXPKC9YUPJ2dRWZTRfxRNVyDXD6/35nCAwMBCApKYmUlBT69u3rGOPn50ePHj3YtGkT48aNIyEhgdzc3CJjQkNDiYiIYNOmTSUW4OjoaGbNmlWFn0ZEpHoYMgQGDXK/das2m7mdW926EB5e/tfl5FRstjk/37y4yaFDRf+yUB6GAcnJ8MADcP310Ly5edSvf37vIyImtynAhmEQFRXFtddeS0REBAApKSkABAcHFxkbHBzMwYMHHWN8fX2pf9bvEsHBwY7XF2fGjBlERUU57hfOAIuIyLm8vaFnT6tTOIevr7mtW0hI+V9jGOY65ZLK8TffQGxs2e/z6qvmUahevT/LcHj4n7ebN4emTc2sInIutynAEyZMYPv27WzcuPGc52xnbRZpGMY5j52trDF+fn74+flVLKyIiMhf2Gzmfsh2u1lOzxYXV74C3KePeVGTpCRISYETJ2DLFvM4m5eXuRSluHLcvDk0aKC9lsVzuUUBnjhxIqtXr2bDhg1Fdm4I+d9fv1NSUmjcuLHj8dTUVMescEhICDk5OaSlpRWZBU5NTaVr165O+gQiIiIl69bNXONb1o4aa9f+ubTk5EnzKnv79597JCWZyy0OHjSP9evPfc/atUuePb74YnN3DJHqyqULsGEYTJw4kVWrVhEXF0f4WYu0wsPDCQkJITY2lo4dOwKQk5NDfHw8c+bMAaBTp07UqFGD2NhYbrvtNgCOHj3Kzp07mTt3rnM/kIiISDG8vc2tzm65xSy7xe2o8cILRddVBwRA27bmcTbDMK/qV1w53r/fLNpZWbB9u3kU56KLSp49DgnR7LG4N5feBeLBBx9k+fLlfPzxx0X2/rXb7dT6314yc+bMITo6msWLF9OiRQtmz55NXFzcOdugffrppyxZsoTAwECmTp3K77//rm3QRETEpThrR40zZ8yZ4ZIKclZW6a+vVevPYnx2QQ4PN8u5iBWqxTZoJa3RXbx4MWPGjAH+vBDGokWLilwIo/BEOYAzZ87w8MMPs3z58iIXwjifk9pUgEVExBmsvhKcYZgn5pVUjpOToaCg9PcIDi55eUVoqOvvECLuq1oUYFeiAiwiImJuA5ecXHJBPnGi9Nf7+pprjEtaXlGZf8Ra/ZcJcb5quQ+wiIiIWMvXFy65xDyKk5ZmnoRXXDk+eNAs0Pv2mUdxgoJKnj0OCwOfcjYXXVZaSqMZ4HLSDLCIiMiFycszT8Arafb4+PHSX+/tDc2alTx7XL++eXKeLivtubQEopKpAIuIiFStzMySZ4+TkszZ49LY7WYx/vFHcxu44ths5jrk3bvNreC8vCr/c1Q37rSURAW4kqkAi4iIWKegwCxgJc0el3Jx11LVqGHualGzpvnzr7fP9+f5jHWX4u1uS0lUgCuZCrCIiIjrKrwwyJIl8O9/W52mbO5QvN1xKYlOghMRERGPUXhhkJtvLl8BXrMGrrzSXCpx5oz586+3K/qztOfy8v789XNzzSMjo+q+k+KUt3j7+cHq1cVfmbDwsXHjIDDQXHpSu/afR0CA689wawa4nDQDLCIi4vry881t1sq6rHRSkvPXseblmWX4Qkp0RYr4X4u3s/j7Fy3FZx916pT+fHFHeXYA0QywiIiIeJyKXFbaWXx8/ixzzlTe4v3Xn//9L7z9dtnvHRJizvZmZZlH4UVSTp0yj9TUyvscfn5ll+QaNcr3XpoBLifNAIuIiLgPZ11WurqKi4Nevcoet3499Oxp3jYMszwXluGSjszMssf8dez5zWBnADoJrtKoAIuIiLgXd9q+y9W40lKSnJzyF+bjxzN46SUV4EqjAiwiIiKepHAXCCh+KYk77wLh4ufoiYiIiIgVhgwxS+5FFxV9vEkT1yy/50MnwYmIiIhIsYYMgUGDqt9SEhVgERERESmRt/efJ7pVF1oCISIiIiIeRQVYRERERDyKCrCIiIiIeBQVYBERERHxKCrAIiIiIuJRVIBFRERExKOoAIuIiIiIR1EBFhERERGPogIsIiIiIh5FBVhEREREPIoKsIiIiIh4FBVgEREREfEoKsAiIiIi4lFUgEVERETEo6gAi4iIiIhHUQEWEREREY/iUQV4wYIFhIeHU7NmTTp16sTXX39tdSQRERERcTKPKcDvvvsukZGRPProo2zdupVu3bpx44038uuvv1odTUREREScyGYYhmF1CGe4+uqrueKKK1i4cKHjsdatWzN48GCio6PLfH1GRgZ2u5309HTq1q1blVFFREREpALK29d8nJjJMjk5OSQkJDB9+vQij/ft25dNmzYV+5rs7Gyys7Md99PT0wHzixURERER11PY08qa3/WIAnz8+HHy8/MJDg4u8nhwcDApKSnFviY6OppZs2ad83hYWFiVZBQRERGRypGZmYndbi/xeY8owIVsNluR+4ZhnPNYoRkzZhAVFeW4f+LECZo1a8avv/5a6hcqpcvIyCAsLIzk5GQtJblA+i4rj77LyqHvsfLou6w8+i4rh7t8j4ZhkJmZSWhoaKnjPKIAN2jQAG9v73Nme1NTU8+ZFS7k5+eHn5/fOY/b7XaX/g/vLurWravvsZLou6w8+i4rh77HyqPvsvLou6wc7vA9lmei0iN2gfD19aVTp07ExsYWeTw2NpauXbtalEpERERErOARM8AAUVFRjBo1is6dO9OlSxdiYmL49ddfuf/++62OJiIiIiJO5DEFeNiwYfz+++889dRTHD16lIiICNasWUOzZs3K9Xo/Pz+efPLJYpdFSPnpe6w8+i4rj77LyqHvsfLou6w8+i4rR3X7Hj1mH2AREREREfCQNcAiIiIiIoVUgEVERETEo6gAi4iIiIhHUQEWEREREY+iAlyGDRs2MGDAAEJDQ7HZbHz00UdWR3JL0dHRXHnlldSpU4dGjRoxePBgfvzxR6tjuaWFCxdy+eWXOzYj79KlC5999pnVsdxedHQ0NpuNyMhIq6O4nZkzZ2Kz2YocISEhVsdyW4cPH+aOO+4gKCgIf39/OnToQEJCgtWx3MrFF198zv+TNpuN8ePHWx3N7eTl5fHYY48RHh5OrVq1aN68OU899RQFBQVWR7sgHrMNWkWdPHmS9u3bM3bsWIYOHWp1HLcVHx/P+PHjufLKK8nLy+PRRx+lb9++7N69m4CAAKvjuZUmTZrw7LPPcumllwLw5ptvMmjQILZu3Urbtm0tTueeNm/eTExMDJdffrnVUdxW27Zt+fLLLx33vb29LUzjvtLS0rjmmmvo1asXn332GY0aNeKXX36hXr16VkdzK5s3byY/P99xf+fOnVx//fXceuutFqZyT3PmzOGVV17hzTffpG3btvzwww+MHTsWu93OpEmTrI5XYSrAZbjxxhu58cYbrY7h9tauXVvk/uLFi2nUqBEJCQl0797dolTuacCAAUXuP/PMMyxcuJBvv/1WBbgCsrKyuP3223n11Vd5+umnrY7jtnx8fDTrWwnmzJlDWFgYixcvdjx28cUXWxfITTVs2LDI/WeffZZLLrmEHj16WJTIfX3zzTcMGjSIm2++GTD/f3znnXf44YcfLE52YbQEQiyRnp4OQGBgoMVJ3Ft+fj4rVqzg5MmTdOnSxeo4bmn8+PHcfPPN9OnTx+oobu2nn34iNDSU8PBwhg8fzv79+62O5JZWr15N586dufXWW2nUqBEdO3bk1VdftTqWW8vJyWHZsmXcdddd2Gw2q+O4nWuvvZZ169axb98+ALZt28bGjRu56aabLE52YTQDLE5nGAZRUVFce+21REREWB3HLe3YsYMuXbpw5swZateuzapVq2jTpo3VsdzOihUr2LJlC5s3b7Y6ilu7+uqreeutt7jsssv47bffePrpp+natSu7du0iKCjI6nhuZf/+/SxcuJCoqCj+8Y9/8P333/PQQw/h5+fHnXfeaXU8t/TRRx9x4sQJxowZY3UUtzRt2jTS09Np1aoV3t7e5Ofn88wzzzBixAiro10QFWBxugkTJrB9+3Y2btxodRS31bJlSxITEzlx4gQffvgho0ePJj4+XiX4PCQnJzNp0iS++OILatasaXUct/bXZWLt2rWjS5cuXHLJJbz55ptERUVZmMz9FBQU0LlzZ2bPng1Ax44d2bVrFwsXLlQBrqDXX3+dG2+8kdDQUKujuKV3332XZcuWsXz5ctq2bUtiYiKRkZGEhoYyevRoq+NVmAqwONXEiRNZvXo1GzZsoEmTJlbHcVu+vr6Ok+A6d+7M5s2befHFF1m0aJHFydxHQkICqampdOrUyfFYfn4+GzZsYP78+WRnZ+tErgoKCAigXbt2/PTTT1ZHcTuNGzc+5y+yrVu35sMPP7QokXs7ePAgX375JStXrrQ6itt6+OGHmT59OsOHDwfMv+QePHiQ6OhoFWCRshiGwcSJE1m1ahVxcXGEh4dbHalaMQyD7Oxsq2O4ld69e7Njx44ij40dO5ZWrVoxbdo0ld8LkJ2dzZ49e+jWrZvVUdzONddcc84Wkfv27aNZs2YWJXJvhSdcF57AJefv1KlTeHkVPWXM29tb26BVd1lZWfz888+O+0lJSSQmJhIYGEjTpk0tTOZexo8fz/Lly/n444+pU6cOKSkpANjtdmrVqmVxOvfyj3/8gxtvvJGwsDAyMzNZsWIFcXFx5+y0IaWrU6fOOWvQAwICCAoK0tr08zR16lQGDBhA06ZNSU1N5emnnyYjI8OtZ4esMnnyZLp27crs2bO57bbb+P7774mJiSEmJsbqaG6noKCAxYsXM3r0aHx8VHcqasCAATzzzDM0bdqUtm3bsnXrVubNm8ddd91ldbQLY0ip1q9fbwDnHKNHj7Y6mlsp7jsEjMWLF1sdze3cddddRrNmzQxfX1+jYcOGRu/evY0vvvjC6ljVQo8ePYxJkyZZHcPtDBs2zGjcuLFRo0YNIzQ01BgyZIixa9cuq2O5rU8++cSIiIgw/Pz8jFatWhkxMTFWR3JLn3/+uQEYP/74o9VR3FpGRoYxadIko2nTpkbNmjWN5s2bG48++qiRnZ1tdbQLYjMMw7CmeouIiIiIOJ/2ARYRERERj6ICLCIiIiIeRQVYRERERDyKCrCIiIiIeBQVYBERERHxKCrAIiIiIuJRVIBFRERExKOoAIuIiIiIR1EBFhERERGPogIsIuKBpkyZwoABA6yOISJiCRVgEREPlJiYSIcOHayOISJiCRVgEREPtG3bNjp27Gh1DBERS6gAi4h4mOTkZH7//XfHDPCJEycYMGAAXbt25ejRo9aGExFxAhVgEREPk5iYiN1uJzw8nB07dnDllVfSuHFj4uLiaNy4sdXxRESqnAqwiIiHSUxMpH379rzzzjt0796dqVOnEhMTg6+vr9XRREScwmYYhmF1CBERcZ6hQ4eyfv16AD799FO6du1qcSIREefSDLCIiIdJTExk6NChnDlzhhMnTlgdR0TE6TQDLCLiQTIzM7Hb7SQkJLBt2zYmTZrEpk2baNu2rdXRREScxsfqACIi4jyJiYl4e3vTpk0bOnbsyK5duxgwYADff/89DRo0sDqeiIhTaAmEiIgH2bZtG61atcLPzw+AOXPm0KZNG4YMGUJOTo7F6UREnENLIERERETEo2gGWEREREQ8igqwiIiIiHgUFWARERER8SgqwCIiIiLiUVSARURERMSjqACLiIiIiEdRARYRERERj6ICLCIiIiIeRQVYRERERDyKCrCIiIiIeBQVYBERERHxKP8PWZLBQF0zvlUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "kmeans_per_k = [KMeans(n_clusters = k, random_state = 42).fit(X)\n",
    "                for k in range(1, 10)]\n",
    "inertias = [model.inertia_ for model in kmeans_per_k]\n",
    "\n",
    "plt.figure(figsize = (8, 3.5))\n",
    "plt.plot(range(1, 10), inertias, \"bo-\")\n",
    "plt.xlabel(\"$k$\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.annotate('Elbow',\n",
    "             xy = (4, inertias[3]),\n",
    "             xytext = (0.55, 0.55),\n",
    "             textcoords = 'figure fraction',\n",
    "             arrowprops = dict(facecolor='black', shrink=0.1)\n",
    "            )\n",
    "plt.axis([1, 8.5, 0, 1300])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee05a5a-3323-42aa-8de6-cb84e0c59929",
   "metadata": {},
   "source": [
    "As you can see, the inertia drops very quickly as we increase *k* up to 4, but then it decreases much more slowly as we keep increasing *k*. This curve has roughly the shape of an arm, & there is an \"elbow\" at $k = 4$ so if we did not know better, it would be a good choice: any lower value would be dramatic, while any higher value would not help much, & we might just be splitting perfectly good clusters in half for no good reason. \n",
    "\n",
    "This technique for choosing the best value for the number of clusters is rather coarse. A more precise approach (but also more computationally expensive) is to use the *silhouette score*, which is the mean *silhouette coefficient* over all the instances. An instance's silhouette coefficient is equal to *(b - a)/max(a, b)* where *a* is the mean distance to the other instances in the same cluster (it is the mean intra-cluster distance), & *b* is the mean nearest-cluster distance, that is the mean distance to the instances of the next closest cluster (defined as the one that minimises *b*, excluding the instance's own cluster). The silhouette coefficient can vary between -1 & +1: a coefficient close to +1 means that the instance is will inside its own cluster & far from other clusters, while a coefficient close to 0 means that it is close to a cluster boundary, & finally a coefficient close to -1 means that the instance may have been assigned to the wrong cluster. To compute the silhouette score, you can use the scikit-learn's `silhouette_score()` function, giving it all the instances in the dataset, & the labels they were assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb1cc0c3-a1d0-4299-8a0e-dfd930c0a211",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6522147691564292"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouette_score(X, kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0ffa5d-4a5a-4578-acb2-e5d92cb126bc",
   "metadata": {},
   "source": [
    "Let's compare the silhouette scores for different numbers of clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5bce2cc-a035-4e74-94dc-6a0b3e78bf7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "silhouette_scores = [silhouette_score(X, model.labels_)\n",
    "                     for model in kmeans_per_k[1:]]\n",
    "\n",
    "plt.figure(figsize = (8, 3))\n",
    "plt.plot(range(2, 10), silhouette_scores, \"bo-\")\n",
    "plt.xlabel(\"$k$\")\n",
    "plt.ylabel(\"Silhouette score\")\n",
    "plt.axis([1.8, 8.5, 0.55, 0.7])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf2b8ed-0edd-4777-9b41-6aba99cc5b14",
   "metadata": {},
   "source": [
    "As you can see, this visualisation is much richer than the previous one: in particular, although it confirms that $k = 4$ is a very good choice, it also underlines the fact that $k = 5$ is quite good as well, & much better than $k = 6$ or $7$. This was not visible when comparing inertias.\n",
    "\n",
    "An even more informative visualisation is obtained when you plot every instance's silhouette coefficient, sorted by the cluster they are assigned to & by the value of the coefficient. This is called a *silhouette diagram*.\n",
    "\n",
    "<img src = \"Images/Silhouette Diagram.png\" width = \"800\" style = \"margin:auto\"/>\n",
    "\n",
    "The vertical dashed lines represent the silhouette score for each number of clusters. When most of the instances in a cluster have a lower coefficient that this score (i.e., if many of the instances stop short of the dashed line, ending to the left of it), then cluster is rather bad since this means its instances are much too close to other clusters. We can see that when $k = 3$ & when $k = 6$, we get bad clusters. But when $k = 4$ or $k = 5$, the clusters look pretty good -- most instances extend beyond the dashed line, to the right & closer to 1.0. When $k = 4$, the cluster at index 1 (the third from the top), is rather big, while when $k = 5$, all clusters have similar sizes, so even though the overall silhouette score from $k = 4$ is slightly greater than for $k = 5$, it seems like a good idea to use $k = 5$ to get clusters of similar sizes.\n",
    "\n",
    "## Limits of K-Means\n",
    "\n",
    "Despite its many merits, most notably being fast & scalable, K-means is not perfect. As we saw, it is necessary to run the algorithm several times to avoid sub-optimal solutions, plus you need to specify the number of clusters, which can be quite a hassle. Moreover, K-means does not behave very well when the clusters have varying sizes, different densities, or non-spherical shapes. For example, the below figure show how K-means clusters a dataset contraining three ellipsoidal clusters of different dimensions, densities & orientations.\n",
    "\n",
    "<img src = \"Images/K-Means Drawbacks.png\" width = \"750\" style = \"margin:auto\"/>\n",
    "\n",
    "As you can see, neither of these solutions are any good. The solution on the left is better, but it still chops off 25% of the middle cluster & assigns it to the cluster on the right. The solution on the right is just terrible, even though its inertia is lower. So depending on the data, different clustering algorithms may perform better. For example, on these types of elliptical clusters, Gaussian mixture models work great.\n",
    "\n",
    "Now let's look at a few ways we can benefit from clustering. We will use K-means, but feel free to experiment with other clustering algorithms.\n",
    "\n",
    "## Using Clustering for Image Segmentation\n",
    "\n",
    "*Image segmentation* is the task of partitioning an image into multiple segments. In *semantic segmentation*, all pixels that are part of the same object type get assigned to the same segment. For example, in a self-driving car's vision system, all pixels that are part of a pedestrians's image might be assigned to the \"pedestrian\" segment (there would just be one segment containing all the pedestrians). In *instance segmentation*, all pixels that are part of the same individual object are assigned to the same segment. In this case, there would be a different segment for each pedestrian. The state of the art in semantic or instance segmentation today is achieved using complex architectures based on convolutional neural networks. Here, we are going to do something much simpler: *colour segmentation*. We will simply assign pixels to the same segment if they have a similar color. In some applications, this may be sufficient, for example if you want to analyse satellite images to measure how much total forest area there is in a region, colour segmentation may be just fine.\n",
    "\n",
    "First, let's load an image using matplotlib's `imread()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cccb0422-120d-4b67-bf57-368c484bf83a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(533, 800, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib.image import imread\n",
    "\n",
    "image = imread(\"Images/ladybug.png\")\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b93bd9e-2b93-4231-82bf-8d4d9f6f8228",
   "metadata": {},
   "source": [
    "The image is represented as a 3D array: the first dimension's size is the height, the second is the width, & the third is the number of colour channels, in this case red, green & blue (RGB). In other words, for each pixel there is 3D vector containing the intensities of red, green & blue, each between 0.0 & 1.0 (or between 0 & 255 if you use `imageio.imread()`). Some images may have less channels, such as gray-scale images (one channel), or more channels, such as images with an additional *alpha channel* for transparency, or satellite images which often contain channels for many light frequencies (e.g., infrared). The following code reshapes the array to get a long list of RGB colours, then its clusters these colours using K-means. For example, it may identify a colour cluster for all shades of green. Next, for each colour (e.g., dark green), it looks for the mean colour of the pixel's colour cluster. For example, all shades of green may be replaced with the same light green colour (assuming the mean colour of the green cluster is light green). Finally it reshapes this long list of colours to get the same shape as the original image. & we're done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "176f7164-21ed-46ef-9cc1-60777ce3d93a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = image.reshape(-1, 3)\n",
    "kmeans = KMeans(n_clusters = 8).fit(X)\n",
    "segmented_img = kmeans.cluster_centers_[kmeans.labels_]\n",
    "segmented_img = segmented_img.reshape(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c1e8ff-4308-4412-b3cf-80ca4d2e7bd2",
   "metadata": {},
   "source": [
    "This outputs the image shown in the upper right of the below figure. You can experiment with various numbers of clusters, as shown in the figure. When you use less than 8 clusters, notice that the ladybug's flashy red colour fails to get a cluster of its own: it gets merged with colours from the environment. This is due to the fact that the ladybug is quite small, much smaller than the rest of the image, so even though its colour is flashy, K-means fails to dedicate a cluster to it: as mentioned earlier, K-means prefers clusters of similar sizes.\n",
    "\n",
    "<img src = \"Images/Image Segmentation with K-Means.png\" width = \"750\" style = \"margin:auto\"/>\n",
    "\n",
    "That wasn't too hard, was it? Now let's look at another application of clustering: preprocessing.\n",
    "\n",
    "## Using Clustering for Preprocessing\n",
    "\n",
    "Clustering can be an efficient approach to dimensionality reduction, in particular as a preprocessing step before a supervised learning algorithm. For example, let's tackle the *digits* dataset which is a simple MNIST-like dataset containing 1797 grayscale 8x8 images representing digits 0 to 9. First, let's load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f3b93e1-1867-4635-a5df-e84c65af8811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "X_digits, y_digits = load_digits(return_X_y = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca3e931-a1bf-4fc9-b5c1-dc3caf119aef",
   "metadata": {},
   "source": [
    "Now, let's split it into a training set & a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74c876be-65e4-46be-94aa-34a8a1bfcca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_digits, y_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a4714f-74d1-41f1-81db-54863da1cd4e",
   "metadata": {},
   "source": [
    "Next, let's fit a logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "175217d4-2db4-4421-a525-385163815cff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=32)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000, random_state=32)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(max_iter = 1000, random_state = 32)\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e690dba2-1688-418b-bf32-7c18ce0ba8bc",
   "metadata": {},
   "source": [
    "Let's evaluate its accuracy on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "731d0a54-0848-4817-b4bb-39fce436f621",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9511111111111111"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b374e7-d1d9-4f74-9697-f35ced0ba1df",
   "metadata": {},
   "source": [
    "Okay, that's our baseline: 98% accuracy. Let's see if we can do better by using K-means as a preprocessing step. We will create a pipeline that will first cluster the training set into 50 clusters & replace the images with their distances to these 50 clusters, then apply a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fcc360e-a4bb-429d-9127-d21adb5f51db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;kmeans&#x27;, KMeans(n_clusters=50)),\n",
       "                (&#x27;log_reg&#x27;, LogisticRegression(max_iter=1000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;kmeans&#x27;, KMeans(n_clusters=50)),\n",
       "                (&#x27;log_reg&#x27;, LogisticRegression(max_iter=1000))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;KMeans<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.cluster.KMeans.html\">?<span>Documentation for KMeans</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>KMeans(n_clusters=50)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('kmeans', KMeans(n_clusters=50)),\n",
       "                ('log_reg', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([(\"kmeans\", KMeans(n_clusters = 50)),\n",
    "                     (\"log_reg\", LogisticRegression(max_iter = 1000))])\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c886f687-dbee-4312-9364-4d60f5d75abc",
   "metadata": {},
   "source": [
    "Now let's evaluate this classification pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60661932-8955-4a5e-94ff-c2a8d221bc5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9711111111111111"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2224b23b-5db2-4e94-ae91-4f7b7949eb0e",
   "metadata": {},
   "source": [
    "We chose the number of clusters *k* arbitrarily, but we can surely do better. Since K-means is just a preprocessing step in a classification pipeline, finding a good value for *k* is much simpler than ealier: there's no need to perform silhouette analysis or minimise the inertia, the best value of *k* is simply the one that results in the best classification performance during cross-validation. Let's use `GridSearchCV` to find the optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7dbad2c-f341-4158-a31f-90be205285c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Takes too long\n",
    "#param_search_space = dict(kmeans__n_clusters = range(2, 100))\n",
    "#grid_search = GridSearchCV(pipeline, param_search_space, cv = 3, verbose = 2)\n",
    "#grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e54fa3d-a3e4-4143-8e09-4ea9cfcc684c",
   "metadata": {},
   "source": [
    "Let's look at the best value for *k*, & the performance of the resulting pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c878adf0-4a12-42ad-8001-52a76435d829",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b380f34c-0424-4f15-be1f-df04b1430f7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffa91cb-7cb0-4d07-b243-dc46cc62e78e",
   "metadata": {},
   "source": [
    "With an optimal number of clusters, we should get a small accuracy boost.\n",
    "\n",
    "## Using Clustering for Semi-Supervised Learning\n",
    "\n",
    "Another use case for clustering is in semi-supervised learning, when we have plenty of unlabeled instances & very few labeled instances. Let's train a logistic regression model on a sample of 50 labeled instances from the digits dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73906c94-126e-4bfc-8677-632e3267bd44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_labeled = 50\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train[:n_labeled], y_train[:n_labeled])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482abbe3-f6a9-4b43-9fcc-346eeb394714",
   "metadata": {},
   "source": [
    "What is the performance of this model on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07610db3-3ec7-4908-a538-6549c0b11869",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c50456-46e5-4c7a-b282-a0340136501d",
   "metadata": {},
   "source": [
    "The accuracy is just 84%; it should come as no surprise that this is much lower than earlier, when we trained the model on the full training set. Let's see how we can do better. First, let's cluster the training set into 50 clusters, then for each cluster, let's find the image closest to the centroid. We will call these images the representative images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ca8a89a-cdad-4e05-a832-cc493d4c492d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k = 50\n",
    "kmeans = KMeans(n_clusters = k)\n",
    "X_digits_dist = kmeans.fit_transform(X_train)\n",
    "representative_digits_idx = np.argmin(X_digits_dist, axis = 0)\n",
    "X_representative_digits = X_train[representative_digits_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d06eb9c-2f52-4daf-b8b7-f4fbec9be706",
   "metadata": {},
   "source": [
    "We can plot these 50 representative digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "695f4889-d281-400d-8232-2ed82a31670d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x200 with 50 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8, 2))\n",
    "for index, X_representative_digit in enumerate(X_representative_digits):\n",
    "    plt.subplot(k // 10, 10, index + 1)\n",
    "    plt.imshow(X_representative_digit.reshape(8, 8), cmap = \"binary\", interpolation = \"bilinear\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebcf9c9-807c-429d-aef3-966552c4770c",
   "metadata": {},
   "source": [
    "Now let's look at each digit & manually label them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4efaa5da-baa8-4975-9b73-54e2276a2074",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_representative_digits = np.array([7, 0, 5, 8, 6, 9, 8, 7, 1, 2,\n",
    "                                    7, 7, 3, 4, 3, 6, 4, 4, 0, 1, \n",
    "                                    1, 4, 9, 4, 5, 5, 3, 2, 2, 5,\n",
    "                                    7, 7, 6, 9, 8, 7, 9, 3, 9, 7,\n",
    "                                    1, 2, 9, 8, 4, 4, 6, 3, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ad0017-a0f6-49dd-8004-2500ab9c9e1b",
   "metadata": {},
   "source": [
    "Now we have a dataset with just 50 labeled instances, but instead of being completely random instances, each of them is a representative image of its cluster. Let's see if the performance is any better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f1a0c61-ec3c-4783-a632-ddbff31eb9f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8844444444444445"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_representative_digits, y_representative_digits)\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd9aca7-f78c-4724-8d37-3cec9141a916",
   "metadata": {},
   "source": [
    "It has improved, even though we are still only training the model on 50 instances. Since it is often costly & painful to label instances, especially when it has to be done manually by experts, it is a good idea to label representative instances rather than just random instances.\n",
    "\n",
    "But perhaps we can go one step further: waht if we propagated the labels to all the other instances in the same cluster? This is called *label propagation*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8cc0884-8beb-4b98-bcf9-20a4450ca14d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train_propagated = np.empty(len(X_train), dtype = np.int32)\n",
    "for i in range(k):\n",
    "    y_train_propagated[kmeans.labels_ == i] = y_representative_digits[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c62aadf-7f10-4c22-91ae-e6586fcb6fcc",
   "metadata": {},
   "source": [
    "Now let's train the model again & look at its performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5fceb8d1-2708-446c-93e6-8f136aef360a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8844444444444445"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(max_iter = 1000)\n",
    "log_reg.fit(X_train, y_train_propagated)\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59986684-ac5c-42dc-af11-d208fa772d99",
   "metadata": {},
   "source": [
    "Nothing. The problem is that we propagated each representative's label to all instances in the same cluster, including the instances located close to the cluster boundaries, which are more likely to be mislabeled. Let's see what happens if we only propagate the labels to the 20% of the instances that are closest to the centroids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "baf93020-c136-4d03-a27c-d57a4c900380",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "percentile_closest = 20\n",
    "\n",
    "X_cluster_dist = X_digits_dist[np.arange(len(X_train)), kmeans.labels_]\n",
    "for i in range(k):\n",
    "    in_cluster = (kmeans.labels_ == i)\n",
    "    cluster_dist = X_cluster_dist[in_cluster]\n",
    "    cutoff_distance = np.percentile(cluster_dist, percentile_closest)\n",
    "    above_cutoff = (X_cluster_dist > cutoff_distance)\n",
    "    X_cluster_dist[in_cluster & above_cutoff] = -1\n",
    "\n",
    "partially_propagated = (X_cluster_dist != -1)\n",
    "X_train_partially_propagated = X_train[partially_propagated]\n",
    "y_train_partially_propagated = y_train_propagated[partially_propagated]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28119b4-d4a8-4b55-baf2-9812bd2c17bd",
   "metadata": {},
   "source": [
    "Now let's train the model again on this partially propagated dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93e3170e-25a6-492f-9583-72740479ee1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9044444444444445"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_partially_propagated, y_train_partially_propagated)\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0d9c37-a55c-4276-9e50-a23b4af1fdfc",
   "metadata": {},
   "source": [
    "Better! With just 50 labeled instances, we got 90.4% performance, which is closer to the performance of the logistic regression on the fully labeled digits dataset (which was 95.1%). This is because the propagated labels are actually pretty good, their accuracy is high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab5e54ce-3fc1-44e2-b5ba-2fdcb495b006",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9656357388316151"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_train_partially_propagated == y_train[partially_propagated])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305fa45e-6c51-44f1-aba2-f406b4465148",
   "metadata": {},
   "source": [
    "Before we move on to gaussian mixture models, let's take a look at DBSCAN, another popular clustering algorithm that illustrates a very different approach based on local density estimation. This approach allows the algorithm to identify clusters of arbitrary shapes.\n",
    "\n",
    "## DBSCAN\n",
    "\n",
    "This algorithm defines clusters as continuous regions of high density. It is actually quite simple.\n",
    "\n",
    "* For each instance, the algorithm counts how many instances are located within a small distance $\\varepsilon$ (epsilon) from it. This region is called the instance's $\\varepsilon$-*neighbourhood*.\n",
    "* If an instance has at least `min_samples` instances in its $\\varepsilon$-neighbourhood (including itself), then it is considered a *core instance*. In other words, core instances are those that all located in dense regions.\n",
    "* All instances in the neighbourhood of a core instance belong to the same cluster. This may include other core instances, therefore a long sequence of neighbouring core instances forms a single cluster.\n",
    "* Any instance that is not a core instance & does not have on in its neighbourhood is considered an anomaly.\n",
    "\n",
    "This algorithm works well if all the clusters are dense enough, & they are well separated by low-density regions. The `DBSCAN` class in scikit-learn is as simple to use as you might expect. Let's test it on the moons dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0da081cd-52a8-42fc-86ed-fa69d7c6178a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DBSCAN(eps=0.05)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DBSCAN<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.cluster.DBSCAN.html\">?<span>Documentation for DBSCAN</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DBSCAN(eps=0.05)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DBSCAN(eps=0.05)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples = 1000, noise = 0.05)\n",
    "dbscan = DBSCAN(eps = 0.05, min_samples = 5)\n",
    "dbscan.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ae9c22-1dda-4db6-8784-eddde543daf5",
   "metadata": {},
   "source": [
    "The labels of all the instances are now available in the `labels_` instance variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc0a7485-63e8-41d5-917a-2a85f0612acc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  0, -1,  1,  2,  3,  3,  0,  4,  2,  5,  5,  4,  1,  4,  4,  0,\n",
       "        4,  0,  2,  2,  4,  0,  2,  6,  7,  5,  0,  7,  2,  4,  2,  4,  6,\n",
       "        8,  4,  2,  0, -1,  2,  2,  0,  1,  4,  0,  2,  1,  2,  6,  7,  0,\n",
       "        0,  2,  0,  5,  2,  6,  2,  4,  2, -1,  4,  4,  2, -1,  4,  0,  2,\n",
       "        5,  5,  2,  2,  2,  2,  5,  6,  2,  6,  2,  2,  5,  0,  0,  5,  4,\n",
       "        2,  2,  0,  5,  6,  2,  1,  4, -1,  7,  2,  2,  2,  0,  5,  0, -1,\n",
       "        4,  6,  1,  5,  4,  5,  4,  5,  2,  2,  4,  2,  2,  2,  4,  2,  2,\n",
       "        2,  2,  2, -1,  0,  5,  6, -1,  2,  2,  5,  4,  5,  2,  0,  6,  0,\n",
       "        2,  2,  1,  2,  5,  0, -1,  4,  0,  2,  5,  1,  1,  2,  2,  0,  4,\n",
       "        2,  2, -1,  4,  7,  1,  0,  0,  0,  5,  2,  3,  6,  0,  2,  4,  4,\n",
       "        4,  5,  6,  2,  1,  2,  2,  0,  4,  0,  0,  4,  4,  2,  6,  5,  0,\n",
       "        2,  0, -1,  2,  2,  0,  2,  0,  2,  2,  2,  4,  8,  6,  2,  2,  6,\n",
       "        4,  0,  2,  6,  2,  7,  4,  0,  0,  0, -1,  2,  0,  2,  4,  5,  8,\n",
       "        8,  8,  2,  5,  2,  2,  2,  2,  2,  4,  0,  5,  0,  1,  1,  2,  2,\n",
       "       -1,  6,  2,  2,  5,  5,  0,  2, -1,  6,  1,  1,  0,  2,  5,  2,  4,\n",
       "        1,  5, -1,  6,  1,  4,  5,  2,  2,  2,  2,  0,  2,  2,  5,  0,  1,\n",
       "        0,  2,  8,  2,  2,  5,  4,  4,  5,  2,  2,  2,  0,  2,  2,  6,  4,\n",
       "       -1,  2,  0,  4,  4,  2,  1,  2,  4,  0,  2,  5,  4,  2, -1,  2,  4,\n",
       "        2, -1,  0,  0,  2,  0,  5,  6,  2,  2,  2,  5, -1, -1,  1,  4,  2,\n",
       "        2,  7,  4, -1,  0,  0,  4,  1, -1,  5,  5,  5,  6,  5,  8,  6,  7,\n",
       "        0,  6,  4,  2,  0,  5,  5,  5,  0,  4,  2,  2,  4,  5,  2,  0,  6,\n",
       "        2,  4,  0,  0,  2,  2,  0,  1,  0,  2,  2,  2,  7,  5,  1,  2,  2,\n",
       "        1,  2,  0,  2,  0,  0,  2,  4,  2, -1,  0,  0,  2,  5,  0,  0,  5,\n",
       "        2,  2, -1,  2,  4,  0,  5,  2,  0, -1,  0,  4,  0, -1,  4,  2,  7,\n",
       "        2,  2,  2,  5, -1,  0,  2,  2,  0,  2,  0, -1,  7,  0,  2,  0,  2,\n",
       "        6,  5, -1,  5,  0,  5,  0,  4,  5,  5,  4,  1,  0,  2, -1,  0,  0,\n",
       "        4,  0,  1,  2,  0,  4,  2,  6,  0,  2,  6,  9,  2,  7,  5,  2,  2,\n",
       "        0,  5,  2,  5,  0,  1,  1,  0,  2,  5,  0,  0,  2,  0,  2,  0,  2,\n",
       "        2,  2,  5,  5,  5,  0,  5,  0,  1,  6,  1,  2,  2,  6,  3,  2,  5,\n",
       "        4,  0,  0,  2, -1,  2,  0,  4,  1,  1, -1,  0,  0,  0,  2,  4,  1,\n",
       "        0,  0,  0,  0,  4,  1,  2,  2,  0,  0,  0,  2,  0,  4, -1,  2,  4,\n",
       "        7,  2, -1,  2,  4,  2,  3, -1,  5,  1,  4,  4,  2,  0,  4,  4,  1,\n",
       "       -1,  6,  5,  2,  4,  1,  4,  2,  5,  4,  2,  6, -1,  4,  5,  0,  2,\n",
       "        4,  4,  6,  1,  2,  2,  5,  2,  0,  0,  5, -1,  4,  2,  9,  2,  0,\n",
       "        2,  2,  6,  0,  0,  0,  6,  2,  2,  5,  7,  2,  2,  5,  4,  1,  5,\n",
       "        6,  6,  1,  1,  7, -1,  0,  2,  5,  4,  2,  0,  2,  1,  7,  4,  2,\n",
       "        6,  2,  5,  4,  2,  0,  2,  8,  2,  2,  2,  6,  1, -1,  7,  2,  2,\n",
       "        1,  2,  5,  2,  2,  2,  1,  0,  0,  2,  1,  0,  2,  2,  6,  4,  2,\n",
       "       -1,  0,  2,  0, -1,  0,  2,  1,  1,  5,  4,  0,  0,  6,  6, -1,  4,\n",
       "        2,  0, -1,  2,  2,  4,  5,  0,  1,  0,  6,  0,  5,  2,  9,  8,  0,\n",
       "       -1,  7, -1,  0,  5,  2,  4,  1,  1,  2,  4,  0,  5,  2,  0,  4,  1,\n",
       "        2,  1,  4, -1,  0,  4,  2,  1,  7,  2,  0,  2,  5,  2,  5,  2,  0,\n",
       "        5,  2,  5,  4,  1,  5,  0,  0,  4,  4,  6,  4,  0,  2,  5,  6,  5,\n",
       "        2,  2,  4,  0,  2,  2,  4,  8,  0,  2,  1,  6,  4,  1,  5,  2,  0,\n",
       "       -1,  2,  2,  5,  1,  4,  0,  2, -1,  0,  6,  0,  6,  2,  2,  1,  2,\n",
       "        0,  2,  8,  0,  1,  5,  1,  4,  2,  0,  2,  0,  4,  2,  4,  1,  2,\n",
       "        2,  0,  7,  2,  0,  0,  0,  4,  5,  0,  0,  2,  5,  2,  2,  2,  4,\n",
       "        1,  1,  0,  6,  2,  0, -1,  2,  2,  4,  2,  3,  2,  4,  1,  5,  4,\n",
       "        2,  6,  0,  5, -1,  5,  2,  0,  0,  7,  0,  0,  2,  0,  2, -1,  2,\n",
       "        2,  4,  2,  5,  2,  6,  5, -1,  2,  2,  5,  5,  4,  0,  1,  2,  5,\n",
       "        4,  0,  5,  2,  5,  6,  7,  5,  2,  2,  2,  4,  0,  2,  2,  2,  1,\n",
       "        1,  1,  1,  8,  5,  4,  2,  5,  4,  6,  2,  2,  1,  1,  2,  4,  6,\n",
       "        1,  4,  2,  1, -1,  6,  2,  4,  4,  2,  4,  2,  2,  0,  2,  2,  5,\n",
       "        2,  2, -1, -1,  2,  4,  4,  9,  2,  2,  2,  0,  0,  4,  7,  5,  6,\n",
       "        1,  6,  0,  1,  4,  1,  1,  2,  2,  1, -1,  4,  2,  5,  2,  2,  2,\n",
       "        5, -1,  0,  1,  5,  5,  2,  3,  5, -1,  5,  2,  4,  4,  5,  0,  2,\n",
       "        2,  2, -1,  2,  2,  5,  0,  0,  2,  1,  0,  1,  0,  2,  2, -1,  8,\n",
       "        5,  0,  5,  2,  7,  0,  4,  1,  2,  2,  4,  6,  0,  0,  6,  2,  4,\n",
       "       -1,  2,  4,  9,  4,  1,  0,  2,  5,  1, -1,  1,  2,  7],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ccab0d-f640-47c2-9581-f931362464ac",
   "metadata": {},
   "source": [
    "Notice that some instances have a cluster index equal to -1: this means that they are considered as anomalies by the algorithm. The indices of the core instances are available in the `core_sample_indices_` instance variable, & the core instances themselves are available in the `components_` instance variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6266973f-b35a-4fe8-8e78-1fe3e23c956f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "798"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dbscan.core_sample_indices_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b124cd29-4333-4d89-a45c-e35a41159cb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   3,   4,   6,   7,   8,   9,  10,  11,  13,  14,  15,  16,\n",
       "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
       "        30,  31,  32,  33,  34,  37,  39,  40,  41,  42,  43,  45,  46,\n",
       "        47,  48,  49,  50,  51,  53,  54,  55,  56,  57,  58,  59,  62,\n",
       "        63,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
       "        77,  78,  79,  80,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  94,  95,  96,  97,  99, 102, 103, 104, 105, 106, 107, 108,\n",
       "       109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 121, 124, 125,\n",
       "       127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
       "       140, 143, 144, 145, 147, 149, 151, 153, 154, 156, 157, 158, 160,\n",
       "       162, 163, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
       "       176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190,\n",
       "       191, 192, 193, 194, 195, 196, 199, 201, 202, 203, 204, 205, 206,\n",
       "       207, 208, 209, 210, 211, 215, 216, 217, 218, 219, 222, 223, 224,\n",
       "       225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
       "       239, 240, 242, 243, 244, 245, 247, 248, 249, 250, 251, 253, 254,\n",
       "       255, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268,\n",
       "       269, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
       "       284, 285, 286, 287, 288, 290, 291, 293, 294, 295, 296, 297, 298,\n",
       "       299, 300, 301, 302, 309, 310, 311, 312, 314, 315, 316, 317, 320,\n",
       "       321, 322, 323, 324, 325, 327, 329, 330, 332, 333, 335, 336, 337,\n",
       "       338, 340, 343, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355,\n",
       "       356, 357, 358, 359, 360, 363, 366, 367, 368, 369, 370, 371, 372,\n",
       "       373, 374, 375, 376, 377, 379, 380, 381, 384, 385, 386, 387, 388,\n",
       "       389, 390, 394, 395, 396, 397, 398, 399, 401, 402, 403, 405, 406,\n",
       "       407, 408, 409, 410, 411, 413, 414, 415, 416, 418, 420, 422, 423,\n",
       "       424, 425, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 440,\n",
       "       441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 454,\n",
       "       455, 456, 457, 458, 459, 460, 461, 462, 464, 465, 466, 467, 468,\n",
       "       469, 470, 472, 473, 474, 475, 477, 478, 479, 480, 481, 482, 485,\n",
       "       486, 487, 491, 492, 493, 494, 495, 496, 498, 499, 500, 501, 504,\n",
       "       506, 507, 508, 509, 510, 511, 512, 513, 515, 516, 517, 518, 519,\n",
       "       520, 521, 522, 523, 525, 526, 527, 528, 530, 531, 532, 533, 535,\n",
       "       536, 537, 538, 539, 540, 541, 542, 543, 545, 546, 547, 548, 550,\n",
       "       551, 553, 554, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565,\n",
       "       566, 567, 568, 569, 570, 571, 573, 574, 576, 577, 578, 579, 580,\n",
       "       581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593,\n",
       "       594, 595, 596, 598, 599, 601, 602, 603, 604, 605, 606, 607, 608,\n",
       "       610, 611, 612, 613, 614, 615, 617, 618, 619, 620, 621, 623, 624,\n",
       "       626, 627, 628, 629, 630, 631, 633, 635, 636, 637, 639, 640, 641,\n",
       "       643, 645, 647, 648, 649, 651, 652, 653, 654, 656, 657, 658, 659,\n",
       "       660, 662, 663, 664, 666, 667, 668, 669, 671, 672, 673, 674, 675,\n",
       "       676, 678, 679, 683, 685, 686, 688, 690, 691, 692, 693, 694, 697,\n",
       "       698, 699, 701, 703, 705, 706, 707, 708, 709, 710, 711, 712, 714,\n",
       "       715, 716, 718, 719, 720, 721, 722, 723, 724, 725, 726, 728, 729,\n",
       "       730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 743, 744,\n",
       "       745, 746, 747, 749, 750, 752, 753, 754, 758, 759, 760, 761, 762,\n",
       "       763, 764, 766, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777,\n",
       "       778, 779, 780, 782, 783, 784, 785, 786, 787, 788, 790, 791, 793,\n",
       "       794, 795, 796, 797, 798, 799, 800, 801, 803, 804, 806, 807, 808,\n",
       "       809, 811, 812, 813, 814, 815, 816, 817, 818, 819, 821, 822, 823,\n",
       "       825, 826, 827, 828, 829, 830, 832, 833, 834, 836, 838, 841, 842,\n",
       "       843, 844, 845, 846, 848, 849, 850, 853, 854, 855, 856, 858, 859,\n",
       "       861, 862, 863, 864, 865, 866, 868, 869, 870, 871, 872, 873, 874,\n",
       "       875, 876, 877, 879, 880, 881, 882, 883, 884, 886, 887, 889, 890,\n",
       "       891, 892, 893, 894, 895, 896, 897, 899, 900, 901, 902, 905, 906,\n",
       "       907, 909, 910, 911, 913, 914, 915, 917, 918, 919, 920, 921, 923,\n",
       "       924, 927, 930, 931, 932, 933, 934, 935, 937, 939, 940, 941, 943,\n",
       "       945, 946, 947, 949, 950, 951, 952, 953, 955, 956, 958, 959, 960,\n",
       "       961, 962, 964, 966, 968, 969, 970, 971, 972, 973, 974, 975, 976,\n",
       "       977, 978, 979, 980, 981, 982, 983, 984, 987, 988, 989, 990, 991,\n",
       "       993, 994, 995, 998, 999], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan.core_sample_indices_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34c78c58-3a23-438a-b405-f13620de2fad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.02226484,  0.02162784],\n",
       "       [ 1.90158828,  0.0723769 ],\n",
       "       [-0.02156031,  0.34951073],\n",
       "       ...,\n",
       "       [ 1.84153923,  0.02843818],\n",
       "       [ 0.95326515, -0.52572287],\n",
       "       [ 2.02247512,  0.40631142]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f5b04d-cda1-43df-ba59-c8c824759868",
   "metadata": {},
   "source": [
    "This clustering is represented in the left plot. As you can see, it identified quite a lot of anomalies, plus 7 different clusters. How disappointing! Fortunately, if we widen each instance's neighbourhood by increasing `eps` to 0.2, we get the clustering on the right, which looks perfect. Let's continue with this model.\n",
    "\n",
    "<img src = \"Images/DBSCAN Clustering with Different Neighbourhood Radii.png\" width = \"700\" style = \"margin:auto\"/>\n",
    "\n",
    "Somewhat surprisingly, the DBSCAN class does not have a `predict()` method, although it has a `fit_predict()` method. In other words, it cannot predict which cluster a new instance belongs to. The rationale for this decision is that several classification algorithms could make sense here, & it is easy enough to train one, for example a `KNeighborsClassifier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "35335de1-e551-4f71-9b90-ab18c648ed7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-7 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-7 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-7 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-7 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-7 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KNeighborsClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier(n_neighbors=50)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=50)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 50)\n",
    "knn.fit(dbscan.components_, dbscan.labels_[dbscan.core_sample_indices_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67b8089-48a6-46dc-af3b-d20eecbf4072",
   "metadata": {},
   "source": [
    "Now, given a few new instances, we can predict which cluster they most likely belong to, & even estimate a probability for each cluster. Note that we only trained them on the core instances, but we could also have chosen to train them on all the instances, or all but the anomalies: this choice depends on the final task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cea9b640-42c9-4b23-a803-d08dcf481216",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 4, 1], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.array([[-0.5, 0], [0, 0.5], [1, -0.1], [2, 1]])\n",
    "knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cab38573-6243-459a-8a78-953ec522c20c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86, 0.  , 0.14, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.38, 0.04, 0.58, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.56, 0.  , 0.  , 0.  , 0.  , 0.  , 0.44, 0.  , 0.  ]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict_proba(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2ed8d5-7613-49c7-806b-cbb4ff6cdf22",
   "metadata": {},
   "source": [
    "The decision boundary is represented here.\n",
    "\n",
    "<img src = \"Images/DBSCAN Decision Boundary.png\" width = \"500\" style = \"margin:auto\"/>\n",
    "\n",
    "Notice that since there is no anomaly in the KNN's training set, the classifier always chooses a cluster, even when that cluster is far away. However, it is fairly straightforward to introduce a maximum distance, in which case the two instances that are far away from both clusters are classified as anomalies. To do this, we can use the `kneighbors()` method of the `KNeighborsClassifier`: given a set of instances, it returns the distances & the indices of the *k* nearest neighbours in the training set (two matrices, each with *k* columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "754777ec-4a6f-469c-a012-7a5fadbb2bf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  2,  3, -1], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dist, y_pred_idx = knn.kneighbors(X_new, n_neighbors = 1)\n",
    "y_pred = dbscan.labels_[dbscan.core_sample_indices_][y_pred_idx]\n",
    "y_pred[y_dist > 0.2] = -1\n",
    "y_pred.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95630e2-3f17-4998-a50d-989ea4c98dd1",
   "metadata": {},
   "source": [
    "In short, DBSCAN is a very simple, yet powerful algorithm, capable of identifying any number of clusters, of any shape, it is robust to outliers, & it has just two hyperparameters (`eps` & `min_samples`). However, if the density varies significantly across the clusters, it can be impossible for it to capture all the clusters properly. Moreover, its computational complexity is roughly $O(m\\ log\\ m)$, making it pretty close to linear with regards to the number of instances. However, scikit-learn's implementation can require up to $O(m^2)$ memory if `eps` is large.\n",
    "\n",
    "## Other Clustering Algorithms\n",
    "\n",
    "Scikit-learn implements several more clustering algorithms that you should take a look at. We cannot cover them all in detail here, but here is a brief overview:\n",
    "\n",
    "* *Agglomerative clustering*: a hierarchy of clusters is built from the bottom up. Think of many tiny bubbles floating on water & gradually attaching to each other until there's just one big group of bubbles. Similarly, at each iteration agglomerative clustering connectes the nearest pair of clusters (starting with individual instances). If you draw a tree with a branch for every pair of clusters that merged, you get a binary tree of clusters, where the leaves are the individual instances. This approach scales very well to large numbers of instances or clusters, it can capture clusters of various shapes, it produces a flexible & informative cluster tree instead of forcing you to choose a particular cluster scale, & it can be used with any pairwise distance. It can scale nicely to large numbers of instances if you provide a connectivity matrix. This is a spare *m* by *m* matrix that indicates which pairs of instances are neighbours (e.g., returned by `sklearn.neighbors.kneighbors_graph()`). Without a connectivity matrix, the algorithm does not scale well to large datasets.\n",
    "* *Birch*: this algorithm was designed specifically for very large datasets, & it can be faster than batch K-means, with similar results, as long as the number of featuresis not too large (< 20). It builds a tree structure during training containing just enough information to quickly assign each new instance to a cluster, without having to store all the instances in the tree: this allows it to use limited memory, while handling huge datasets.\n",
    "* *Mean-shift*: this algorithm starts by placing a circle centered on each instance, then for each circle it computes the mean of all the instances located within it, & it shifts the circle so that it is centered on the mean. Next, it iterates this mean-shift step until all the circles stop moving (i.e., until each of them is centered on the mean of the instances it contains). This algorithm shifts the circles in the direction of higher density, untill each of them has found a local density maximum. Finally, all the instances whose circles have settled in the same place (or close enough) are assigned to the same cluster. This has some of the same features as DBSCAN, in particular it can find any number of clusters of any shape, it has just one hyperparameter (the radius of the circles, called the bandwidth) & it relies on local density estimation. However, it tends to chop clusters into pirces when they have internal density variations. Unfortunately, its computational complexity is $O(m^2)$, so it is not suited for large datasets.\n",
    "* *Affinity propagation*: this algorithm uses a voting system, where instances vote for similar instances to be their representatives, & once the algorithm converges, each representative & its voters form a cluster. This algorithm can detect any number of clusters of different sizes. Unfortunately, this algorithm has a computational complexity of $O(m^2)$, so it is not suited for large datasets.\n",
    "* *Spectral clustering*: this algorithm takes a similarity matrix between the instances & creates a low-dimensional embedding from it (i.e., it reduces it dimensionality), then it uses another clustering algorithm in this low-dimensional space (scikit-learn's implementation uses K-means). Spectral clustering can capture complex cluster structures, & it can also be used to cut graphs (e.g., to identify clusters of friends on a social network), however it does not scale well to large number of instances, & it does not behave well when the clusters have very different sizes.\n",
    "\n",
    "Now let's dive into Gaussian mixture models, which can be used for density estimation, clustering & anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bb5347-2d4f-4b34-8c5b-26dc3f214aa5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c2b045-ca62-4808-af23-460a0572b95f",
   "metadata": {},
   "source": [
    "# Gaussian Mixtures\n",
    "\n",
    "A *gaussian mixture model* (GMM) is a probabilistic model that assumes that the instances were generated from a mixture of several gaussian distributions whose parameters are unknown. All the instances generated from a single gaussian distribution form a cluster that typically looks like an ellipsoid. Each cluster can have a different ellipsoidal shape, size, density, & orientation. When you observe an instance, you know it was generated from one of the gaussian distributions, but you are not told which one, & you do not know what the parameters of these distributions are.\n",
    "\n",
    "There are several GMM variants. In the simplest variant, implemented in the `GaussianMixture` class, you must know in advance the number *k* of gaussian distributions. The dataset $X$ is assumed to have been generated through the following probabilistic process:\n",
    "\n",
    "* For each instance, a cluster is picked randomly from among *k* clusters. The probability of choosing the $j^{th}$ cluster is defined by the cluster's weight, $\\phi^{(j)}$. The index of the cluster chosen for the $i^{th}$ instance is noted $z^{(i)}$.\n",
    "* If $z^{(i)} = j$, meaning the $i^{th}$ instance has been assigned to the $j^{th}$ cluster, the location $x^{(i)}$ of this instance is sampled randomly from the gaussian distribution with mean $\\mu^{(j)}$ & covariance matrix $\\sum^{(j)}$. This is noted $x^{(i)} \\sim \\cal{N}(\\mu^{(j)}, \\sum^{(j)})$.\n",
    "\n",
    "This generative process can be represented as a graphical model. This figure represents the structure of the conditional dependencies between random variables.\n",
    "\n",
    "<img src = \"Images/Gaussian Mixtures.png\" width = \"500\" style = \"margin:auto\"/>\n",
    "\n",
    "Here is how to interpret the figure:\n",
    "\n",
    "* The circles represent random variables.\n",
    "* The squares represente fixed values (i.e., parameters of the model).\n",
    "* The large rectangles are called *plates*. They indicate that their content is repeated several times.\n",
    "* The number at the bottom right of each plate indicates how many times its content is repeated. So, there are *m* random variables $z^{(i)}$ (from $z^{(1)}$ to $z^{(m)}$) & *m* random variables $x^{(i)}$. There are also *k* means $\\mu^{(j)}$& *k* covariance matrices $\\sum^{(j)}$. Lastly, there is just one weight vector $\\phi$ (containing all the weights $\\phi^{(1)}$ to $\\phi^{(k)}$).\n",
    "* Each variable $z^{(i)}$ is drawn from the *categorical distribution* with weights $\\phi$. Each variable $x^{(i)}$ is drawn from the normal distribution, with the mean & covariance matrix defined by its cluster $z^{(i)}$.\n",
    "* The solid arrows represent conditional dependencies. For example, the probability distribution for each random variable $z^{(i)}$ depends on the weight vector $\\phi$. Note that when an arrow crosses a plate boundary, it means that it applies to all the repetitions of that plate. For example, the weight vector $\\phi$ conditions the probability distributions of all the random variables $x^{(1)}$ to $x^{(m)}$.\n",
    "* The squiggly arrow from $z^{(i)}$ to $x^{(i)}$ represents a switch: depending on the value of $z^{(i)}$, the instance $x^{(i)}$ will be sampled from a different gaussian distribution. For example, if $z^{(i)} = j$, then $x^{(i)} \\sim \\cal{N}(\\mu^{(j)}, \\sum^{(j)})$.\n",
    "* Shaded nodes indicate that the value is known. So, in this case, only the random variables $x^{(i)}$ have known values: they are called *observed variables*. The unknown random variables $z^{(i)}$ are called *latent variables*.\n",
    "\n",
    "So, what can you do with such a model? Well, given the dataset $X$, you typically want to start by estimating the weights $\\phi$ & all the distribution parameters $\\mu^{(1)}$ to $\\mu^{(k)}$ & $\\sum^{(1)}$ to $\\sum^{(k)}$. Scikit-learn's `GaussianMixture` class makes this super easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb92ccfe-00a1-4713-8fcb-cc1045857672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gm = GaussianMixture(n_components = 3, n_init = 10)\n",
    "gm.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135aaa11-0bfb-46bf-bec9-4066bf3ac218",
   "metadata": {},
   "source": [
    "Let's look at the parameters that the algorithm estimated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5469c3-b501-4525-9290-c73a43f1e7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.weights_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16614ce8-b65a-4fbc-847a-041a699671a5",
   "metadata": {},
   "source": [
    "gm.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82673a8-a1d2-46e0-ae39-ab7ce1d43b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.covariances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e562bfe9-a5a1-47c8-9cc1-ea37db441a45",
   "metadata": {},
   "source": [
    "Great, it worked! Indeed, the weights that were used to generate the data were 0.2, 0.4, & 0.4; & similarly, the means & covariance matrices were very close to those found by the algorithm. But how? This class relies on the *Expectation-Maximization* (EM) algorithm, which has many similarities with the K-menas algorithm: it also initialises the cluster parameters randomly, then it repeats two steps until convergence, first assigning instances to clusters (this is called the *expectation step*) & then updating the cluster (this is called the *maximisation step*). Sounds familiar, right? In the context of clustering, you can think of EM as a generalisation of K-means that not only finds the cluster centers ($\\mu^{(1)}$ to $\\mu^{(k)}$), but also their size, shape, & orientation ($\\sum^{(1)}$ to $\\sum^{(k)}$), as well as their relative weights ($\\phi^{(1)}$ to $\\phi^{(k)}$). Unlike K-means, though, EM uses soft cluster assignments, not hard assignments. For each instance, during the expectation step, the algorithm estimates the probability that it belongs to each cluster (based on the current cluster parameters). Then, during the maximization step, each cluster is updated using *all* the instances in the dataset, with each instance weighted by the estimated probability that it belongs to that cluster. These probabilities are called the *responsibilities* of the clusters for the instances.\n",
    "\n",
    "During the maximization step, each cluster's update will mostly be impacted by the instances it is most responsible for.\n",
    "\n",
    "You can check whether or not the algorithm converged & how many iterations it took:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7723b7cf-2ecc-4219-90f1-aa74ddea73c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.converged_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11849aac-e72f-414f-ad25-36717b497e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299e9ce5-854e-471d-809a-92b3e554a777",
   "metadata": {},
   "source": [
    "Now that you have an estimate of the location, size, shape, orientation, & relative weight of each cluster, the model can easily assign each instance to the most likely cluster (hard clustering) or estimate the probability that it belongs to a particular cluster (soft clustering). Just use the `predict()` method for hard clustering, or `predict_proba()` method for soft clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cc4e02-1cca-4639-9419-9f098c6dbdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c535f89-4380-4bee-ab91-19ae4b764da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c06da06-5b6e-4a1c-a367-07ebb0e86c24",
   "metadata": {},
   "source": [
    "A gaussian mixture model is a *generative model*, meaning you can sample new instances from it (note that they are ordered by cluster index):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ad21dc-ad8f-4e38-aa24-9e61785aa0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new, y_new = gm.sample(6)\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac93ff45-5538-4fad-b2b7-7c382c4250e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d6613a-50d5-4593-b282-1eeccff55d2f",
   "metadata": {},
   "source": [
    "It is also possible to estimate the density of the model at any given location. This is achieved using the `score_samples()` method: for each instance it is given, this method estimates the log of the *probability density function* (PDF) at that location. The freater the score, the higher the density:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd12a36-d150-4a5c-bb12-87f96cb0b549",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.score_samples(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec639e6-57ca-4ab2-9178-176415f25b78",
   "metadata": {},
   "source": [
    "If you compute the exponential of these scores, you get the value of the PDF at the location of the given instances. These are not probabilities, but probabilities *densities*: they can take on any positive value, not just a value between 0 & 1. To estimate the probability that an instance will fall within a particular region, you would have to integrate the PDF over that region (if you do so over the entire space of possible instance locations, the result will be 1).\n",
    "\n",
    "The figure shows the cluster means, the decision boundaries (dashed lines), & the density contours of this model.\n",
    "\n",
    "<img src = \"Images/Cluster Means Decision Boundaries Density Contours.png\" width = \"500\" style = \"margin:auto\"/>\n",
    "\n",
    "Nice! The algorithm clearly found an excellent solution. Of course, we made its task by generating the data using a set of 2D gaussian distributions (unfortunately, real-life data is not always so gaussian & low-dimensional). We also gave the algorithm the correct number of clusters. When there are many dimensions, or many clusters, or few instances, EM can struggle to converge to the optimal solution. You might need to reduce the difficulty of the task by limiting the number of parameters that the algorithm has to learn. One way to do this is to limit the range of shapes & orientations that the clusters can have. This can be achieved by imposing constraints on the covariance matrices. To do this, set the `covariance_type` hyperparameter to one of the following values:\n",
    "\n",
    "* `\"spherical\"`: All clusters must be spherical, but they can have different diameters (i.e., different variances).\n",
    "* `\"diag\"`: Clusters can take on any ellipsoidal shape of any size, but the ellipsoid's axes must be parallel to the coordinate axes (i.e., the covariance matrices must be diagonal).\n",
    "* `\"tied\"`: All clusters must have the same ellipsoidal shape, size, & orientation (i.e., all clusters share the same covariance matrix).\n",
    "\n",
    "By default, `covariance_type` is equal to `\"full\"`, which means that each cluster can take on any shape, size, & orientation (it has its own unconstrained covaraince matrix). This figure plotsthe solutions found by the EM algorithm when `covariance_type` is set to `\"tied\"` or `\"spherical\"`.\n",
    "\n",
    "<img src = \"Images/Tied Clusters vs Spherical Clusters.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "Gaussian mixture models can also be used for anomaly detection. Let's see how.\n",
    "\n",
    "## Anomaly Detection Using Gaussian Mixtures\n",
    "\n",
    "*Anomaly detection* (also called *outlier detection*) is the task of detecting instances that deviate strongly from the norm. These instances are called *anomalies*, or *outliers*, while the normal instances are called *inliers*. Anomaly detection is useful in a wide variety of applications, such as fraud detection, detecting defective products in manufacturing, or removing outliers from a dataset before training another model (which can significantly improve the performance of the resulting model).\n",
    "\n",
    "Using a gaussian mixture model for anomaly detection is quite simple: any instance located in a low-density region can be considered an anomaly. You must define what density threshold you want to use. For example, in a manufacturing company that tries to detect defective products, the ratio of defective products is usually well known. Say it is equal to 4%. You then set the density threshold to be the value that results in having 4% of the instances located in areas below that threshold density. If you notice that you get too many false positives (i.e., perfectly good products that are flagged as defective), you can lower the threshold. Conversely, if you have too many false negatives (i.e., defective products that the system does not flag as defective), you can increase the threshold. This is the usual precision/recall trade-off. Here is how you would identify the outliers using the fourth percentile lowest density as the threshold (i.e., approximately 4% of the instances will be flagged as anomalies):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cb862c-0f06-4ebc-96f6-149522dc5309",
   "metadata": {},
   "outputs": [],
   "source": [
    "densities = gm.score_samples(X)\n",
    "density_threshold = np.percentile(densities, 4)\n",
    "anomalies = X[densities < density_threshold]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f827f7-114c-443d-b32a-4cf816a20af0",
   "metadata": {},
   "source": [
    "We can represent these anomalies as stars.\n",
    "\n",
    "<img src = \"Images/Anomaly Detection with Gaussian Mixture Models.png\" width = \"500\" style = \"margin:auto\"/>\n",
    "\n",
    "A closely related task is *novelty detection*: it differs from anomaly detection in that the algorithm is assumed to be trained on a \"clean\" dataset, uncontaminated by outliers, whereas anomaly detection does not make this assumption. Indeed, outlier detection is often used to clean up a dataset.\n",
    "\n",
    "Just like K-means, the `GaussianMixture` algorithm requires you to specify the number of clusters. So, how can you find it?\n",
    "\n",
    "## Selecting the Number of Clusters\n",
    "\n",
    "With K-means, you could use the inertia or the silhouette score to select the appropriate number of clusters. But with gaussian mixtures, it is not possible to use these metrics because they are not reliable when the clusters are not spherical or have different sizes. Instead, you can try to find the model that minimises a *theoretical information criterion* such as the *Bayesian information criterion* (BIC) or the *Akaiki information criterion* (AIC).\n",
    "\n",
    "$$BIC = log(m)p - 2log(\\hat{L})$$\n",
    "$$AIC = 2p - 2log(\\hat{L})$$\n",
    "\n",
    "In these equations:\n",
    "\n",
    "* *m* is the number of instances, as always.\n",
    "* *p* is the number of parameters learned by the model.\n",
    "* $\\hat{L}$ is the maximised value of the *likelihood function* of the model. \n",
    "\n",
    "Both the BIC & the AIC penalise models that have more parameters to learn (e.g., more clusters) & reward models that fit the data well. They often end up selecting the same model. When they differ, the model selected by the BIC tends to be simpler (fewer parameters) than the one selected by the AIC, but tends to not fit the data quite as well (this is especially true for larger datasets).\n",
    "\n",
    "To compute the BIC & AIC, call the `bic()` & `aic()` methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7e44f4-c170-44a6-a768-cf14181004b3",
   "metadata": {},
   "source": [
    "gm.bic(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f407e66-1f62-43a3-8f0c-5c76f7b4aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.aic(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e226f85-885c-493d-84dc-eb623066ae98",
   "metadata": {},
   "source": [
    "We can show how AIC & BIC behave for different numbers of clusters *k*.\n",
    "\n",
    "<img src = \"Images/AIC & BIC vs K.png\" width = \"500\" style = \"margin:auto\"/>\n",
    "\n",
    "## Likelihood Function\n",
    "\n",
    "The terms \"probability\" & \"likelihood\" are often used interchangeably in the English language, but they have very different meanings in statistics. Given a statistical model with some parameters $\\theta$, the word \"probability\" is used to describe how plausible a future outcome $x$ is (knowing the parameter values $\\theta$), while the word \"likelihood\" is used to describe how plausible a particular set of parameter values $\\theta$ are, after the outcome $x$ is known.\n",
    "\n",
    "<img src = \"Images/Likelihood Function.png\" width = \"500\" style = \"margin:auto\"/>\n",
    "\n",
    "Consider a 1D mixture model of two gaussian distributions centered at -4 & +1. For simplicity, this toy model has a single parameter $\\theta$ that controls the standard deviations of both distributions. The top-left contour plot shows the entire model $f(x; \\theta)$ as a function of both $x$ & $\\theta$. To estimate the probability distribution of a future outcome $x$, you need to set the model parameter $\\theta$. For example, if you set $\\theta$ to 1.3 (the horizontal line), you get the probability density function $f(x; \\theta = 1.3)$ shown in the lower-left plot. Say you want to estimate the probability that $x$ will fall between -2 & +2. You must calculate the integral of the PDF on this range (i.e., the surface of the shaded region). But what if you don't know $\\theta$, & instead if you have observed a single instance $x = 2.5$ (the vertical line in the upper-left plot)? In this case, you get the likelihood function $\\cal{L}(\\theta|x = 2.5) = f(x = 2.5; \\theta)$, represented in the upper-right plot.\n",
    "\n",
    "In short, the PDF is a function of $x$ (with $\\theta$ fixed), while the likelihood function is a function of $\\theta$ (with $x$ fixed). It is important to understand that the likelihood function is *not* a probability distribution: if you integrate a probability distribution over all possible values of $x$, you always get 1; but if you integrate the likelihood function over all possible values of $\\theta$, the result can be any positive value.\n",
    "\n",
    "Given a dataset $X$, a common task is to try to estimate the most likely values for the model parameters. To do this, you must find the values that maximise the likelihood function, given $X$. In this example, if you have observed a single instance $x = 2.5$, the *maximum likelihood estimate* (MLE) of $\\theta$ is $\\hat{\\theta} = 1.5$. If a prior probability distribution $g$ over $\\theta$ exists, it is possible to take it into account by maximizing $\\cal{L}(\\theta|x)g(\\theta)$ rather than just maximizing $\\cal{L}(\\theta | x)$. This is called *maximum a-posteriori* (MAP) estimation. Since MAP constrains the parameter values, you can think of it as a regularised version of MLE.\n",
    "\n",
    "Notice that maximising the likelihood function is equivalent to maximising its logarithm (represented in the lower-righthand plot). Indeed the logarithm is a strictly increasing function, so if $\\theta$ maximises the log likelihod, it also maximises the likelihood. It turns out that it is generally easier to maximise the log likelihood. For example, if you observed several independent instance $x^{(i)}$ to $x^{(m)}$, you would need to find the value of $\\theta$ that maximises the product of the individual likelihood functions. But it is equivalent, & much simpler, to maximise the sum (not the product) of the log likelihood functions, thanks to the magic of the logarithm which converts products into sums: $log(ab) = log(a) + log(b)$.\n",
    "\n",
    "Once you have estimate $\\hat{\\theta}$, the value of $\\theta$ that maximises the likelihood function, then you are ready to compute $\\hat{L} = \\cal{L} (\\hat{\\theta}, X)$, which is the value used to compute the AIC & BIC; you can think of it as a measure of how well the model fits the data.\n",
    "\n",
    "## Bayesian Gaussian Mixture Models\n",
    "\n",
    "Rather than manually searching for the optimal number of clusters, you can use the `BayesianGaussianMixture` class, which is capable of giving weights equal (or close) to zero to unnecessary clusters. Set the number of clusters `n_components` to a value that you have a good reason to believe is greater than the optimal number of clusters (this assumes some minimal knowledge about the problem at hand), & the algorithm will eliminate the unnecessary clusters automatically. For example, let's set the number of cluster to 10 & see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f4b03c-5bbf-46ed-9706-41a9c8a87e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "\n",
    "bgm = BayesianGaussianMixture(n_components = 10, n_init = 10)\n",
    "bgm.fit(X)\n",
    "np.round(bgm.weights_, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9bf3ad-4626-42c3-9f36-e43df7acf4fc",
   "metadata": {},
   "source": [
    "Perfect: the algorithm automatically detected that only three clusters are needed, & the resulting clusters are almost identifcal to the ones from before: 0.4, 0.2, 0.4.\n",
    "\n",
    "In this model, the cluster parameters (including the weights, means, & covariance matrices) are not treated as fixed model parameters anymore,but as latent random variables, like the cluster assignments. So $z$ now includes both the cluster parameters & the cluster assignments.\n",
    "\n",
    "The beta distribution is commonly used to model random variables whose values lie within a fixed range. In this case, the range is from 0 to 1. The stick-breaking process (SBP) is best explained through an example: suppose $\\phi$ = [0.3, 0.6, 0.5, ...], then 30% of the instances will be assigned to cluster 0, then 60% of the remaining instances will be assigned to cluster 1, then 50% of the remaining instances will be assigned to cluster 2, & so on. This process is a good model for datasets where the new instances are more likely to join large clusters than small clusters (e.g., people are more likely to move to larger cities). If the concentration $\\alpha$ is high, then $\\phi$ values will likely be close to 0, & the SBP generate many clusters. Conversely, if the concentration is low, then $\\phi$ values will likely be close to 1, & there will be few clusters. Finally, the Wishard distribution is used to sample covariance matrices: the parameters $d$ & $V$ control the distribution of cluster shapes.\n",
    "\n",
    "<img src = \"Images/Bayesian Gaussian Mixture Model.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "Prior knowledge about the latent variables $z$ can be encoded in a probability distribution $p(z)$ called the *prior*. For example, we have a prior belief that the clusters are likely to be few (low concentration), or conversely, that they are likely to be plentiful (high concentration). This prior belief about the number of clusters can be adjusted using the `weight_concentration_prior` hyperparameter. Setting it to 0.01 or 10,000 gives very different clusterings. The more data we have, however, the less the priors matter. In fact, to plot diagrams with such large differences, you must use very strong priors & little data.\n",
    "\n",
    "<img src = \"Images/Different Priors vs # of Clusters.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "Bayes' theorem tells us how to update the probability distribution over the latent variables after we observe some data $X$. It computes the *posterior* distribution $p(z|X)$, which is the conditional probability of $z$ given $X$.\n",
    "\n",
    "$$p(z|X) = posterior = \\frac{likelihood\\ x\\ prior}{evidence} = \\frac{p(X|z)p(z)}{p(X)}$$\n",
    "\n",
    "Unfortunately, in a gaussian mixture model (& many other problems), the denominator $p(x)$ is intractable, as it requires integrating over all the possible values of $z$., which would require considering all possible combinations of cluster parameters & cluster assignments.\n",
    "\n",
    "$$p(X) = \\int p(X|z)p(z) dz$$\n",
    "\n",
    "This intractability is one of the central problems in bayesian statistics, & there are several approaches to solving it. One of them is *variational inference*, which picks a family of distributions $q(z, \\lambda)$ with its own *variational parameters* $\\lambda$ (lambda), then optimises these parameters to make $q(z)$ a good approximation of $p(z|X)$. This is achieved by finding the value of $\\lambda$ that minimises the KL divergence from $q(z)$ to $p(z|X)$, noted $D_{KL}(q||p)$. The KL divergence equation is shown, & it can be rewritten as the log of the evidence ($log\\ p(X)$) minus the *evidence lower bound* (ELBO). Since the log of the evidence does not depend on $q$, it is a constant term, so minimising the KL divergence just requires maximising the ELBO.\n",
    "\n",
    "$$\\begin{split}\n",
    "D_{KL}(q||p) = \\mathbb{E}_q [log \\frac{q(z)}{p(z|X)}] \\\\\n",
    "= \\mathbb{E}_q [log\\ q(z) - log\\ p(z|X)] \\\\\n",
    "= \\mathbb{E}_q [log\\ q(z) - log\\ \\frac{p(z, X)}{p(X)}] \\\\\n",
    "= \\mathbb{E}_q [log\\ q(z) - log\\ p(z|X) + log\\ p(X)] \\\\\n",
    "= \\mathbb{E}_q [log\\ q(z)] - \\mathbb{E}_q [log\\ p(z, X)] + \\mathbb{E}_q [log\\ p(X)] \\\\\n",
    "= \\mathbb{E}_q [log\\ p(X)] - (\\mathbb{E}_q [log\\ p(z, X)] - \\mathbb{E}_q [log\\ q(Z)]) \\\\\n",
    "= log\\ p(X) - ELBO \\\\\n",
    "where\\ ELBO = \\mathbb{E}_q [log\\ p(z, X)] - \\mathbb{E}_q [log\\ q(z)]\n",
    "\\end{split}$$\n",
    "\n",
    "In practice, there are different techniques to maximise the ELBO. In *mean field variational inference*, it is necessary to pick the family of distributions $q(z; \\lambda)$ & the prior $p(z)$ very carefully to ensure that the equiation for the ELBO simplifies to a form that can be computed. Unfortunately, there is no general way to do this. Picking the right family of distributions & the right prior depends on the task & requires some mathmatical skills. For example, the distributions & lower-bound euqations used in scikit-learn's `BayesianGaussianMixture` class are presented in the documentation. From these equations, it is possible to derive update equations for the cluster parameters & assignment variables: these are then used very much like in expectation-maximisation algorithm. In fact, the computational complexity of the `BayesianGaussianMixture` class similar to that of the `GaussianMixture` class (but generally significantly slower). A simpler approach to maximizing the ELBO is called *black box stochastic variational inference (BBSVI): at each iteration, a few samples are drawn from $q$, & they are used to estimate the gradients of the ELBO with regard to the variational parameters $\\lambda$, which are then used in a gradient ascent step. This approach makes it possible to use bayesian inference with any kind of model (provided it is differentiable), even deep neural networks; using bayesian inference with deep neural networks is called bayesian deep learning.\n",
    "\n",
    "Gaussian mixture models work great on clusters with ellipsoidal shapes, but if you try to fit a dataset with different shapes, you may have bad surprises. For example, let's see what happens if we use a bayesian gaussian mixture model to cluster the moons dataset.\n",
    "\n",
    "<img src = \"Images/Bayesian Gaussian Mixture Model.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "Oops! The algorithm desperately searched for ellipsoids, so it found eight different clusters instead of two. The density estimation is not too bad, so this model could perhaps be used for anomaly detection, but it failed to identify the two moons. Let's now look at a few clustering algorithms capable of dealing with arbitrarily shaped clusters.\n",
    "\n",
    "## Other Algorithms for Anomaly & Novelty Detection\n",
    "\n",
    "Scikit-learn implements other algorithms dedicated to anomaly detection or novelty detection:\n",
    "\n",
    "* *PCA (& any other dimensionality reduction technique with an `inverse_transform()` method)*\n",
    "   - If you compare the reconstruction error of a normal instance with the reconstruction error of an anomaly, the latter will usually be much larger. This is a simple & often quite efficient anomaly detection approach.\n",
    "* *Fast-MCD (minimum covariance determinant)*\n",
    "   - Implemented by the `EllipticEnvelope` class, this algorithm is useful for outlier detection, in particular to clean up a dataset. It assumes that the normal instances (inliers) are generated from a single gaussian distribution (not a mixture). It also assumes that the dataset is contaminated with outliers that were not generated from this gaussian distribution. When the algorithm estimates the parameters of the gaussian distribution (i.e., the shape of the elliptic envelope around the inliers), it is careful to ignore the instances that are most likely outliers. This technique gives a better estimation of the elliptic envelope & thus makes the algorithm better at identifying the outliers.\n",
    "* *Isolation Forest*\n",
    "   - This is an efficient algorithm for outlier detection, especially in high-dimensional datasets. The algorithm builds a random forest in which each decision tree is grown randomly; at each node, it picks a feature randomly, then pickts a random threshold value (between the min & max values) to split the dataset in two. The dataset gradually gets chopped into pieces this way, until all instances end up isolated from the other instances. Anomalies are usually far from other instances, so on average (across all the decision trees) they tend to get isolated in fewer steps than normal instances.\n",
    "* *Local Outlier Factor (LOF)*\n",
    "   - This algorithm is also good for outlier detection. It compares the density of instances around a given instance to the density around its neighbours. An anomaly is often more isolated than its *k* nearest neighbours.\n",
    "* *One-class SVM*\n",
    "   - This algorithm is better suited for novelty detection. Recall that a kernelised SVM classifier separates two classes by first (implicitly) mapping all the instances to a high-dimensional space, then separating the two classes using a linear SVM classifier within this high-dimensional space. Since we just have one class of instances, the one-class SVM algorithm instead tries to separate the instances in high-dimensional space from the origin. In the original space, this will correspond to finding a small region that encompasses all the instances. If a new instance does not fall within this region, it is an anomaly. There are a few hyperparameters to tweak: the usual ones for the kernelised SVM, plus a margin hyperparameter that corresponds to the probability of a new instance being mistakenly considered as novel when it is in fact normal. It works great, especially with high-dimensional datasets, but like all SVMs, it does not scale to large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d87e4a-ef83-4987-93a6-7dd32e136d41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
