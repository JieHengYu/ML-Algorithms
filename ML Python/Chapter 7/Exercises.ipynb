{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd4135f-f7a7-4208-ba17-552449fb1158",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "1. If you have trained 5 different models on the exact same training data, & they all achieve 95% precision, is there any chance that you can combine these models to get better results? If so, how? If not, why?\n",
    "2. What is the difference between hard & soft voting classifiers?\n",
    "3. Is it possible to speed up training of a bagging ensemble by distributing it across multiple servers? What about pasting ensembles, boosting ensembles, random forests, or stacking ensembles?\n",
    "4. What is the benefit of out-of-bag evaluation?\n",
    "5. What makes extra-trees more random than regular random forests? How can this extra randomness help? Are extra-trees slower or faster than regular random forests?\n",
    "6. If your AdaBoost ensemble underfits the training data, which hyperparameters should you tweak & how?\n",
    "7. If your gradient boosting ensemble overfits the training set, should you increase or decrease the learning rate?\n",
    "8. Load the MNIST data, & split it into a training set, a validation set, & a test set (e.g., use 50,000 instances for training, 10,000 for validation, & 10,000 for testing). Then train various classifiers, such as a random forest classifier, an extra-trees classifier, & a SVM classifier. Next, try to combine them into an ensemble that outperforms each individual classifier on the validation set, using soft or hard voting. Once you have found one, try it on the test set. How much better does it perform compared to the individual classifiers?\n",
    "9. Run the individual classifers from the previous exercise to make predictions on the validation set, & create a new training set with the resulting predictions: each training instance is a vector containing the set of predictions from all your classifiers for an image, & the target is the image's class. Train a classifier on this new training set. Congratulations, you have just trained a blender, & together with the classifiers it forms a stacking ensemble! Now evaluate the ensemble on the test set. For each image in the test set, make predictions with all your classifiers, then feed the predictions to the blender to get the ensemble's predictions. how does it compare to the voting classifier you trained earlier?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f3b557-213b-4729-861e-00fb04dfe437",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf377a0-b6bd-4f82-8d11-73d654cbb501",
   "metadata": {},
   "source": [
    "1. Yes, it is possible. If the models are sufficiently different from one another (independent), they can combine to achieve a higher precision. However, since all models are trained on the same data, it is likely that they will make similar errors, which could reduce the ensemble's precision.\n",
    "2. Hard voting classifiers aggregate the predictions of its predictors & predicts the class that gets the most votes for any given instance. Soft margin classifiers aggregates the class probabilities of each predictor & predicts the class that gets the highest average probability for any given instance.\n",
    "3. Yes for bagging, pasting, random forests. Boosting won't see much of a difference in training time because they train their predictors sequentially. For stacking, you can train each layer in parallel or on multiple servers, but like boosting, they (predictors) need to wait for the predictors in the previous layer to finish training before they can be trained.\n",
    "4. With bagging, since a portion of the training instances are not sampled at all, bagging models can be evaluated on those training instances. It will give you an estimate of how well your model will perform on the test set.\n",
    "5. With random forests, it is generally trained with bagging, so there are random subsets of the training set used to train the model. It also searches for the best feature among a random subset of features when splitting a node (greedy CART algorithm, always want to minimise the weighted sum of gini impurities). The extra-trees introduces more randomness by randomly selecting a feature to split for a node. This increases the bias, but lowers the variance of our model. It also makes extra-trees faster, because it doesn't have to find the best feature to split at every node, as it is one of the most time-consuming tasks of growing a tree.\n",
    "6. You can increase the number of estimators in your AdaBoost ensemble. You should also tweak the hyperparameters of your base estimator to increase complexity.\n",
    "7. If your gradient boosting ensemble overfits the training set, you should increase the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2c5442-7299-49a4-a971-68bd59e85f2a",
   "metadata": {},
   "source": [
    "# 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "828aa2b1-e330-45c8-8d26-20dec14493a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "mnist = fetch_openml(\"mnist_784\", version = 1, as_frame = False)\n",
    "mnist.keys()\n",
    "X, y = mnist[\"data\"].astype(np.intc), mnist[\"target\"].astype(np.intc)\n",
    "\n",
    "strat_split = StratifiedShuffleSplit(n_splits = 1, test_size = 10000, random_state = 32)\n",
    "for train_index, test_index in strat_split.split(X, y):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test = X[test_index], y[test_index]\n",
    "for train_index, val_index in strat_split.split(X_train, y_train):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_val, y_val = X[val_index], y[val_index]\n",
    "    \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.fit_transform(X_val)\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b7e054a-b7fe-4f56-a1ed-141f70b15963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 0.9646\n",
      "ExtraTreesClassifier 0.9687\n",
      "SVC 0.9764\n",
      "HardVotingClassifier 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "forest_classifier = RandomForestClassifier()\n",
    "extratrees_classifier = ExtraTreesClassifier()\n",
    "svm_classifier = SVC()\n",
    "hardvoting_classifier = VotingClassifier(estimators = [(\"forest\", forest_classifier), \n",
    "                                                       (\"extratrees\", extratrees_classifier), \n",
    "                                                       (\"svc\", svm_classifier)],\n",
    "                                         voting = \"hard\")\n",
    "\n",
    "for count, classifier in enumerate([forest_classifier, extratrees_classifier, svm_classifier, hardvoting_classifier]):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_val)\n",
    "    if count != 3:\n",
    "        print(classifier.__class__.__name__, accuracy_score(y_val, y_pred))\n",
    "    else:\n",
    "        print(f\"Hard{classifier.__class__.__name__}\", accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e6e36f8-3115-4957-92c5-01920f7ea589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 0.9648\n",
      "ExtraTreesClassifier 0.9677\n",
      "SVC 0.9764\n",
      "SoftVotingClassifier 0.9751\n"
     ]
    }
   ],
   "source": [
    "forest_classifier = RandomForestClassifier()\n",
    "extratrees_classifier = ExtraTreesClassifier()\n",
    "svm_classifier = SVC(probability = True)\n",
    "softvoting_classifier = VotingClassifier(estimators = [(\"forest\", forest_classifier), \n",
    "                                                       (\"extratrees\", extratrees_classifier), \n",
    "                                                       (\"svc\", svm_classifier)],\n",
    "                                         voting = \"soft\")\n",
    "for count, classifier in enumerate([forest_classifier, extratrees_classifier, svm_classifier, softvoting_classifier]):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_val)\n",
    "    if count != 3:\n",
    "        print(classifier.__class__.__name__, accuracy_score(y_val, y_pred))\n",
    "    else:\n",
    "        print(f\"Soft{classifier.__class__.__name__}\", accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3fb614-552d-40ca-8434-617b27fe5ab4",
   "metadata": {},
   "source": [
    "The soft voting classifier performs slightly better than the hard voting classifier. Let's see if this is the case for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14915f10-1bfa-40a7-b36e-d8cb9b59fb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 0.9899\n",
      "ExtraTreesClassifier 0.9908\n",
      "SVC 0.9846\n",
      "HardVotingClassifier 0.9915\n"
     ]
    }
   ],
   "source": [
    "forest_classifier = RandomForestClassifier()\n",
    "extratrees_classifier = ExtraTreesClassifier()\n",
    "svm_classifier = SVC()\n",
    "hardvoting_classifier = VotingClassifier(estimators = [(\"forest\", forest_classifier), \n",
    "                                                       (\"extratrees\", extratrees_classifier), \n",
    "                                                       (\"svc\", svm_classifier)],\n",
    "                                         voting = \"hard\")\n",
    "\n",
    "for count, classifier in enumerate([forest_classifier, extratrees_classifier, svm_classifier, hardvoting_classifier]):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    if count != 3:\n",
    "        print(classifier.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "    else:\n",
    "        print(f\"Hard{classifier.__class__.__name__}\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a28a7e8-b892-4cd5-a26e-16aa534418f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 0.9898\n",
      "ExtraTreesClassifier 0.99\n",
      "SVC 0.9846\n",
      "SoftVotingClassifier 0.9929\n"
     ]
    }
   ],
   "source": [
    "forest_classifier = RandomForestClassifier()\n",
    "extratrees_classifier = ExtraTreesClassifier()\n",
    "svm_classifier = SVC(probability = True)\n",
    "softvoting_classifier = VotingClassifier(estimators = [(\"forest\", forest_classifier), \n",
    "                                                       (\"extratrees\", extratrees_classifier), \n",
    "                                                       (\"svc\", svm_classifier)],\n",
    "                                         voting = \"soft\")\n",
    "for count, classifier in enumerate([forest_classifier, extratrees_classifier, svm_classifier, softvoting_classifier]):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    if count != 3:\n",
    "        print(classifier.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "    else:\n",
    "        print(f\"Soft{classifier.__class__.__name__}\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f8848b-2c65-444d-9ff0-130eb2fd6111",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84d13e0-ede1-4791-810e-dec4b6dcec68",
   "metadata": {},
   "source": [
    "# 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108d7b2b-1c4e-430f-af57-908ed58b496f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
